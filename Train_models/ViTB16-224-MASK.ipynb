{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNqrhfDrVT0R6BVBX86ftZw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-m-1yfy8W0X7","executionInfo":{"status":"ok","timestamp":1748529520877,"user_tz":-120,"elapsed":18549,"user":{"displayName":"Thesis Bats","userId":"13415237238781601803"}},"outputId":"5875f90d-ef2c-4373-cb8d-81c31c26642a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/LOOCV_2models_withmasks/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT.zip /content\n","!unzip /content/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT.zip -d /content > /dev/null"],"metadata":{"id":"zMUulQLeW4N5","executionInfo":{"status":"ok","timestamp":1748529533993,"user_tz":-120,"elapsed":13114,"user":{"displayName":"Thesis Bats","userId":"13415237238781601803"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["```markdown\n","# -----------------------------------------------------------------------------\n","# Script Structure Overview\n","# -----------------------------------------------------------------------------\n","# 1. Configuration: Import modules, define paths, set random seed, and list candidate gîtes.\n","# 2. Held-out Selection: Randomly choose one gîte for validation to ensure reproducibility.\n","# 3. Directory Preparation: Discover classes and create corresponding validation subdirectories.\n","# 4. File Movement Function: Encapsulate logic to move images and masks for a specific class.\n","# 5. Execution Loop: Iterate over all classes, move matching files, and report counts.\n","# 6. Summary: Print the total number of moved pairs, indicating completion of the split.\n","```"],"metadata":{"id":"4vWstA6ZkX_K"}},{"cell_type":"code","source":["import os\n","import random\n","import shutil\n","\n","# -----------------------------------------------------------------------------\n","# Configuration\n","# -----------------------------------------------------------------------------\n","# Define the base directory containing training and validation data subfolders.\n","base_path = \"/content/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT\"\n","train_img_dir = os.path.join(base_path, \"train_images\")  # Path to training images\n","train_mask_dir = os.path.join(base_path, \"train_masks\")   # Path to training masks\n","val_img_dir = os.path.join(base_path, \"val_images\")      # Destination for validation images\n","val_mask_dir = os.path.join(base_path, \"val_masks\")     # Destination for validation masks\n","\n","# Set a fixed random seed to ensure reproducibility of the held-out selection.\n","RANDOM_SEED = 42\n","random.seed(RANDOM_SEED)\n","\n","# List of candidate gîte identifiers. One will be randomly selected for validation.\n","chosen_gites = [\n","    'Pont_de_Bousval_Photos_2022_PHOTO',\n","    'Modave_Camera_3_toiture_PHOTO',\n","    'Bornival_PHOTO_2023CAM04',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_WK6HDBOUSVAL',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_2022CAM12',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_2023CAM06',\n","    'Bornival_PHOTO_2023CAM03',\n","    'Chaumont_Gistoux_Camera_2',\n","    'Chaumont_Gistoux_Camera_1',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_2023CAM05',\n","    'Jenneret_Camera_1_PHOTO',\n","    'Modave_Camera_plancher_PHOTO'\n","]\n","\n","# Randomly choose one gîte to hold out for the validation set.\n","held_out_gite = random.choice(chosen_gites)\n","print(f\"Holding out gîte for validation: {held_out_gite}\")\n","print(f\"Reproducible with seed: {RANDOM_SEED}\")\n","\n","# -----------------------------------------------------------------------------\n","# Prepare validation directories per class\n","# -----------------------------------------------------------------------------\n","# Identify classes by listing subdirectories in the training image directory.\n","classes = [d for d in os.listdir(train_img_dir)\n","           if os.path.isdir(os.path.join(train_img_dir, d))]\n","\n","# Ensure the base validation directories exist.\n","os.makedirs(val_img_dir, exist_ok=True)\n","os.makedirs(val_mask_dir, exist_ok=True)\n","\n","# Create class-specific subdirectories inside the validation folders.\n","for cls in classes:\n","    os.makedirs(os.path.join(val_img_dir, cls), exist_ok=True)\n","    os.makedirs(os.path.join(val_mask_dir, cls), exist_ok=True)\n","\n","\n","def move_class_images_and_masks(cls, gite_name):\n","    \"\"\"\n","    Move all images and their corresponding masks belonging to a specific class\n","    and matching the held-out gîte identifier into the validation directories.\n","\n","    Args:\n","        cls (str): Name of the class subdirectory.\n","        gite_name (str): Identifier of the held-out gîte to match in filenames.\n","\n","    Returns:\n","        int: Number of image-mask pairs successfully moved.\n","    \"\"\"\n","    src_img_cls = os.path.join(train_img_dir, cls)\n","    src_mask_cls = os.path.join(train_mask_dir, cls)\n","    dst_img_cls = os.path.join(val_img_dir, cls)\n","    dst_mask_cls = os.path.join(val_mask_dir, cls)\n","    moved = 0\n","\n","    for fname in sorted(os.listdir(src_img_cls)):\n","        if gite_name in fname:\n","            img_src = os.path.join(src_img_cls, fname)\n","            base, _ = os.path.splitext(fname)\n","            mask_name = f\"{base}_mask.png\"\n","            mask_src = os.path.join(src_mask_cls, mask_name)\n","\n","            if os.path.exists(mask_src):\n","                # Move both image and mask to the validation directory\n","                shutil.move(img_src, os.path.join(dst_img_cls, fname))\n","                shutil.move(mask_src, os.path.join(dst_mask_cls, mask_name))\n","                moved += 1\n","            else:\n","                # Warn if a mask is expected but missing\n","                print(f\"Warning: Mask not found for {cls} image: {fname}\")\n","\n","    return moved\n","\n","# -----------------------------------------------------------------------------\n","# Execution: Move files for all classes and report summary\n","# -----------------------------------------------------------------------------\n","total_moved = 0\n","for cls in classes:\n","    moved_count = move_class_images_and_masks(cls, held_out_gite)\n","    print(f\"Class '{cls}': moved {moved_count} image-mask pairs\")\n","    total_moved += moved_count\n","\n","print(f\"Total moved {total_moved} image-mask pairs to validation.\")\n"],"metadata":{"id":"MgRrEnFgW-ec"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loo CV Masked-Bat Classifier (Google Colab Setup)\n","\n","This script implements a leave-one-out cross-validation (LoO CV) pipeline to train and evaluate a binary image classifier that distinguishes bats from background using masked inputs and a pretrained Vision Transformer (ViT).\n","\n","## Features\n","- **Leave-one-out cross-validation** for robust evaluation on small datasets  \n","- **Masked inputs**: background masking using per-image binary masks  \n","- **Data augmentations** plus MixUp/CutMix for better generalization  \n","- **Custom Focal Loss** to combat class imbalance  \n","- **Partial freezing** of ViT encoder layers for efficient transfer learning  \n","- **Automatic threshold selection** via Precision–Recall curve  \n","- **ROC curve plotting** and AUC computation  \n","- **Inference** on test set with mask application and decision threshold  \n","\n","## Directory Structure\n","```\n","/content/loo_temp_<site>_<camera>Camera<fold>/\n","├── train_images/\n","│ ├── background/\n","│ └── bats/\n","├── train_masks/\n","│ ├── background/\n","│ └── bats/\n","├── val_images/\n","│ ├── background/\n","│ └── bats/\n","├── val_masks/\n","│ ├── background/\n","│ └── bats/\n","├── test_images/\n","│ ├── background/\n","│ └── bats/\n","└── test_masks/\n","├── background/\n","└── bats/\n","```\n","Each image in `*_images/` should have a corresponding mask in `*_masks/` named `<image_basename>_mask.png`. Folders are organized by class (`background`/`bats`).\n","\n","---\n","\n","## Key Modules\n","\n","### 1. Configuration\n","- Defines dataset directories, output paths, random seed, batch size, number of epochs, and learning rate  \n","- Sets up device (GPU/CPU), mixed-precision (AMP), and reproducibility  \n","\n","### 2. Transforms & Augmentation\n","- **Image Transforms**:  \n","  - `RandomResizedCrop`, `RandomHorizontalFlip`, `RandomRotation`, `ColorJitter`  \n","  - `RandomPerspective`, `GaussianBlur`, `RandomErasing`  \n","  - Normalize to ±1 range  \n","- **Mask Transforms**:  \n","  - Resize with nearest neighbor  \n","  - Binarize to 0/1 mask  \n","- **MixUp/CutMix**:  \n","  - Batch-wise application with configurable α parameters  \n","\n","### 3. Data Handling\n","- **`MaskedImageDataset`**  \n","  - Loads images and masks, applies transforms, multiplies image by mask  \n","  - Returns `(masked_image, label)`  \n","- **DataLoaders**  \n","  - **Training**: `WeightedRandomSampler`, prefetching, persistent workers  \n","  - **Validation/Test**: Sequential loading  \n","\n","### 4. Partial Freezing of Encoder Layers\n","- **Freeze first two-thirds** of transformer encoder blocks to retain pretrained weights and speed up training\n","\n","### 5. Loss Function\n","- **Focal Loss**  \n","  - α = [0.05, 0.95]  \n","  - γ = 2.0  \n","  - Focuses on hard examples and down-weights easy ones\n","\n","### 6. Optimizer & Scheduler\n","- **Optimizer**: AdamW, learning rate = 3e-5  \n","- **Scheduler**: CosineAnnealingLR over total training steps\n","\n","### 7. Training & Validation Loop\n","1. **Training**  \n","   - Mixed precision (`autocast` + `GradScaler`)  \n","   - MixUp/CutMix augmentation  \n","   - Forward/backward pass, optimizer step, scheduler step  \n","2. **Validation**  \n","   - Forward only  \n","   - Compute validation loss and macro precision  \n","3. **Early Stopping**  \n","   - Stop if no macro F1 improvement for 3 consecutive epochs  \n","4. **Checkpointing**  \n","   - Save best model weights and validation logits/labels  \n","\n","### 8. Threshold Optimization & ROC Analysis\n","- Load validation logits and labels  \n","- Compute Precision–Recall curve and select threshold where precision ≈ recall  \n","- Compute ROC curve and AUC, plot with threshold marker  \n","\n","### 9. Inference on Test Set\n","- Reload best model and optimal threshold  \n","- For each test image:  \n","  1. Apply mask if available  \n","  2. Forward pass → probability  \n","  3. Apply threshold → “bats” vs “background”  \n","  4. Print filename, predicted class, probability, and mask usage  \n","\n","### 10. Final Evaluation\n","- Generate classification report (precision, recall, F1) on test set  \n","- Plot ROC curve for test predictions  \n","\n","---\n","\n","## Hardware Requirements\n","- **GPU** recommended (e.g., NVIDIA T4 on Colab) for mixed-precision  \n","- Falls back to CPU if no CUDA device is available  \n","\n","## Outputs\n","- `best.pth`: Model checkpoint with highest validation F1  \n","- `blob.pt`: Validation logits & labels for threshold tuning  \n","- `thr.txt`: Selected optimal threshold value  \n","- Inline ROC plot with AUC and threshold marker  \n","\n","## Notes\n","- Adjust `NUM_EPOCHS`, `BATCH_SIZE`, and `LEARNING_RATE` to match dataset size and hardware  \n","- Ensure masks are correctly paired and binary (0/1)  \n","- For full LoO CV, wrap the script in an outer loop over folds  \n","- Enable `torch.compile()` on PyTorch ≥2.0 for additional speed gains  "],"metadata":{"id":"bUyRHZn0eZjD"}},{"cell_type":"code","source":["\"\"\"\n","LoO CV masked-bat classifier with train/val/test splits, augmentations, MixUp/CutMix,\n","FocalLoss, ViT head freezing, and inference.\n","\"\"\"\n","import os\n","import random\n","import shutil\n","import math\n","import json\n","from collections import Counter\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","from torchvision import transforms\n","from torchvision.transforms import InterpolationMode\n","from PIL import Image\n","from tqdm.auto import tqdm\n","from timm.data.mixup import Mixup\n","from transformers import ViTForImageClassification\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from sklearn.metrics import (\n","    precision_score, recall_score, f1_score,\n","    precision_recall_curve, roc_curve, auc\n",")\n","import matplotlib.pyplot as plt\n","\n","# --------------------------\n","# CONFIGURATION\n","# --------------------------\n","DATA_DIR       = \"/content/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT\"\n","TRAIN_IMG_DIR  = os.path.join(DATA_DIR, \"train_images\")\n","TRAIN_MASK_DIR = os.path.join(DATA_DIR, \"train_masks\")\n","VAL_IMG_DIR    = os.path.join(DATA_DIR, \"val_images\")\n","VAL_MASK_DIR   = os.path.join(DATA_DIR, \"val_masks\")\n","TEST_IMG_DIR   = os.path.join(DATA_DIR, \"test_images\")\n","TEST_MASK_DIR  = os.path.join(DATA_DIR, \"test_masks\")\n","\n","\n","# reproducibility\n","SEED = 42\n","random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","# --------------------------\n","# HYPERPARAMS\n","# --------------------------\n","BATCH_SIZE    = 32\n","NUM_EPOCHS    = 10\n","LEARNING_RATE = 3e-5\n","MODEL_NAME    = \"google/vit-base-patch16-224\"\n","OUTPUT_DIR    = \"/content/drive/MyDrive/LOOCV_results/vit_masked_loocv\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# --------------------------\n","# DEVICE & AMP\n","# --------------------------\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.backends.cudnn.benchmark = True\n","torch.set_float32_matmul_precision('high')\n","try:\n","    from torch.amp import autocast, GradScaler\n","    AMP_KW = dict(device_type='cuda')\n","except ImportError:\n","    from torch.cuda.amp import autocast, GradScaler\n","    AMP_KW = {}\n","scaler = GradScaler()\n","\n","# --------------------------\n","# TRANSFORMS + MIXUP/CUTMIX\n","# --------------------------\n","normalize = transforms.Normalize((0.5,)*3, (0.5,)*3)\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224, scale=(0.5,1.0), ratio=(0.9,1.1), interpolation=InterpolationMode.BICUBIC),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n","    transforms.RandomPerspective(distortion_scale=0.3, p=0.3),\n","    transforms.GaussianBlur(kernel_size=3, sigma=(0.1,2.0)),\n","    transforms.ToTensor(),\n","    normalize,\n","    transforms.RandomErasing(scale=(0.02,0.2), ratio=(0.3,3.3), p=0.25),\n","])\n","val_transform = transforms.Compose([\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","    normalize,\n","])\n","\n","mixup_fn = Mixup(\n","    mixup_alpha=0.2, cutmix_alpha=1.0,\n","    prob=0.5, switch_prob=0.5,\n","    mode='batch', label_smoothing=0.0,\n","    num_classes=2\n",")\n","\n","# mask transform\n","mask_transform = transforms.Compose([\n","    transforms.Resize((224,224), interpolation=Image.NEAREST),\n","    transforms.ToTensor(),\n","    transforms.Lambda(lambda t: (t>0.5).float()),\n","])\n","\n","# --------------------------\n","# DATASET\n","# --------------------------\n","class MaskedImageDataset(Dataset):\n","    EXT = {'.jpg','.jpeg','.png','.bmp','.tiff'}\n","    def __init__(self, img_root, mask_root, img_tfm=None, mask_tfm=None):\n","        self.img_root, self.mask_root = img_root, mask_root\n","        self.img_tfm, self.mask_tfm = img_tfm, mask_tfm\n","        self.classes = sorted(d.name for d in os.scandir(img_root) if d.is_dir())\n","        self.cls2idx = {c:i for i,c in enumerate(self.classes)}\n","        self.samples, self.targets = [], []\n","        for c in self.classes:\n","            for fn in os.listdir(os.path.join(img_root,c)):\n","                if os.path.splitext(fn)[1].lower() not in self.EXT: continue\n","                ip = os.path.join(img_root,c,fn)\n","                mp = os.path.join(mask_root,c, os.path.splitext(fn)[0] + '_mask.png')\n","                mp = mp if os.path.isfile(mp) else None\n","                self.samples.append((ip, mp)); self.targets.append(self.cls2idx[c])\n","    def __len__(self): return len(self.samples)\n","    def __getitem__(self, idx):\n","        ip, mp = self.samples[idx]; label = self.targets[idx]\n","        img = Image.open(ip).convert('RGB')\n","        if self.img_tfm: img = self.img_tfm(img)\n","        if mp is not None:\n","            m = Image.open(mp).convert('L')\n","            m = self.mask_tfm(m) if self.mask_tfm else m\n","        else:\n","            m = torch.ones(1, *img.shape[1:], dtype=img.dtype)\n","        img = img * m\n","        return img, label\n","\n","# --------------------------\n","# DATASPLITS & LOADERS\n","# --------------------------\n","train_set = MaskedImageDataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, img_tfm=train_transform, mask_tfm=mask_transform)\n","val_set   = MaskedImageDataset(VAL_IMG_DIR, VAL_MASK_DIR, img_tfm=val_transform, mask_tfm=mask_transform)\n","# test (for metrics)\n","test_set  = MaskedImageDataset(TEST_IMG_DIR, TEST_MASK_DIR, img_tfm=val_transform, mask_tfm=mask_transform)\n","\n","# balanced sampler\n","targs = torch.tensor(train_set.targets)\n","cnts  = torch.tensor([Counter(targs.tolist())[i] for i in range(len(train_set.classes))], dtype=torch.float)\n","cls_w = 1./cnts; cls_w /= cls_w.sum()\n","samp_w= cls_w[targs]\n","sampler = WeightedRandomSampler(samp_w, num_samples=len(train_set)*2, replacement=True)\n","\n","num_w = os.cpu_count() or 2\n","train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, sampler=sampler,\n","                          num_workers=num_w, pin_memory=True,\n","                          persistent_workers=True, prefetch_factor=4)\n","val_loader = DataLoader(val_set, batch_size=BATCH_SIZE*2, shuffle=False,\n","                        num_workers=num_w, pin_memory=True,\n","                        persistent_workers=True)\n","test_loader = DataLoader(test_set, batch_size=BATCH_SIZE*2, shuffle=False,\n","                         num_workers=num_w, pin_memory=True,\n","                         persistent_workers=True)\n","\n","# --------------------------\n","# LOSS\n","# --------------------------\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n","        super().__init__()\n","        self.alpha = torch.tensor(alpha, dtype=torch.float32) if isinstance(alpha,(list,tuple)) else alpha\n","        self.gamma, self.reduction = gamma, reduction\n","    def forward(self, logits, targets):\n","        ce = F.cross_entropy(logits, targets, reduction='none')\n","        pt = torch.exp(-ce)\n","        if isinstance(self.alpha, torch.Tensor):\n","            a = self.alpha.to(logits.device)[targets] if targets.dtype in (torch.int64,torch.int32) else self.alpha.mean()\n","        else: a = self.alpha\n","        loss = a * (1-pt)**self.gamma * ce\n","        return loss.mean() if self.reduction=='mean' else loss.sum()\n","\n","# --------------------------\n","# MODEL + FREEZE\n","# --------------------------\n","base = ViTForImageClassification.from_pretrained(\n","    MODEL_NAME, num_labels=2,\n","    id2label={0:'background',1:'bats'}, label2id={'background':0,'bats':1},\n","    ignore_mismatched_sizes=True\n",").to(DEVICE)\n","# custom head\n","embed_dim = base.classifier.in_features\n","base.classifier = nn.Sequential(nn.Dropout(0.5), nn.Linear(embed_dim, 2)).to(DEVICE)\n","# freeze first 2/3\n","blocks = base.vit.encoder.layer if hasattr(base,'vit') else base.encoder.layer\n","freeze_upto = int(len(blocks)*2/3)\n","for i,blk in enumerate(blocks):\n","    if i < freeze_upto:\n","        for p in blk.parameters(): p.requires_grad=False\n","try: model = torch.compile(base)\n","except: model = base\n","\n","# optimizer & scheduler\n","loss_fn = FocalLoss(alpha=[0.05,0.95], gamma=2.0).to(DEVICE)\n","opt     = AdamW(model.parameters(), lr=LEARNING_RATE)\n","sch     = CosineAnnealingLR(opt, T_max=NUM_EPOCHS*len(train_loader))\n","\n","# --------------------------\n","# TRAIN/VAL LOOP\n","# --------------------------\n","best_f1, noimp = 0.0, 0; patience=3\n","for epoch in range(1, NUM_EPOCHS+1):\n","    model.train(); train_loss=0.0\n","    for x,y in tqdm(train_loader, desc=f'Train {epoch}/{NUM_EPOCHS}'):\n","        x,y = x.to(DEVICE), y.to(DEVICE)\n","        x,y = mixup_fn(x,y)\n","        with autocast(**AMP_KW): logits = model(pixel_values=x).logits; loss=loss_fn(logits,y)\n","        opt.zero_grad(); scaler.scale(loss).backward(); scaler.step(opt); scaler.update(); sch.step()\n","        train_loss += loss.item()\n","    avg_tr = train_loss/len(train_loader)\n","    # validation\n","    model.eval(); vloss=0.0; preds, labs = [], []\n","    with torch.no_grad():\n","        for x,y in tqdm(val_loader, desc='Valid'):\n","            x,y=x.to(DEVICE),y.to(DEVICE)\n","            with autocast(**AMP_KW): out=model(pixel_values=x).logits; loss=loss_fn(out,y)\n","            vloss+=loss.item(); preds.append(out.cpu()); labs.append(y.cpu())\n","    val_logits = torch.cat(preds); val_labs = torch.cat(labs)\n","    avg_val = vloss/len(val_loader)\n","    p_m = precision_score(val_labs, val_logits.argmax(1), average='macro')\n","    if p_m>best_f1:\n","        best_f1, noimp = p_m, 0\n","        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR,'best.pth'))\n","        torch.save({'logits':val_logits,'labels':val_labs}, os.path.join(OUTPUT_DIR,'blob.pt'))\n","    else:\n","        noimp+=1\n","        if noimp>=patience: print('Early stop'); break\n","    print(f\"Epoch {epoch}: TrainL={avg_tr:.4f}, ValL={avg_val:.4f}, F1_macro={p_m:.4f}\")\n","\n","# --------------------------\n","# THRESHOLD & ROC\n","# --------------------------\n","blob = torch.load(os.path.join(OUTPUT_DIR,'blob.pt'))\n","labels = blob['labels'].numpy(); probs = blob['logits'].softmax(1)[:,1].numpy()\n","prec,rec,thr = precision_recall_curve(labels,probs)\n","best_thr=thr[np.argmin(abs(prec-rec))]\n","with open(os.path.join(OUTPUT_DIR,'thr.txt'),'w') as f: f.write(str(best_thr))\n","fpr,tpr,rt = roc_curve(labels,probs); auc_v=auc(fpr,tpr)\n","plt.figure(figsize=(6,6))\n","plt.plot(fpr,tpr,label=f'AUC={auc_v:.3f}')\n","pt = np.argmin(abs(rt-best_thr))\n","plt.scatter(fpr[pt],tpr[pt],s=50,label=f'thr={best_thr:.3f}')\n","plt.plot([0,1],[0,1],'k--',alpha=0.4)\n","plt.xlabel('FPR'); plt.ylabel('TPR'); plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()\n","\n","# --------------------------\n","# INFERENCE ON TEST\n","# --------------------------\n","print(\"\\nRunning inference on test set…\")\n","\n","# initialize the lists to hold ground‐truths and preds\n","y_true, y_pred = [], []\n","\n","model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, 'best.pth')))\n","model.eval()\n","thr = float(open(os.path.join(OUTPUT_DIR,'thr.txt')).read())\n","\n","# iterate with indices so we can pull the true label\n","for idx, (ip, mp) in enumerate(test_set.samples):\n","    # load & transform\n","    img = Image.open(ip).convert('RGB')\n","    it = val_transform(img)\n","    if mp and os.path.isfile(mp):\n","        mimg = Image.open(mp).convert('L')\n","        mt = mask_transform(mimg)\n","        it *= mt\n","        used = '(mask)'\n","    else:\n","        used = ''\n","    # forward\n","    with torch.no_grad(), autocast(**AMP_KW):\n","        lg = model(pixel_values=it.unsqueeze(0).to(DEVICE)).logits\n","    p = lg.softmax(1)[0,1].item()\n","    pred_class = 1 if p >= thr else 0\n","    # record\n","    y_true.append(test_set.targets[idx])\n","    y_pred.append(pred_class)\n","    # print\n","    pr = 'bats' if pred_class == 1 else 'background'\n","    print(f\"{os.path.basename(ip)}: {pr} (P={p:.3f}) {used}\")\n","\n","# now you have y_true and y_pred defined\n","from sklearn.metrics import classification_report\n","print(\"Classification Report:\")\n","print(classification_report(y_true, y_pred, target_names=['background', 'bats']))\n","\n"],"metadata":{"id":"2_5m5l6vXEPN"},"execution_count":null,"outputs":[]}]}