{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMBJ2futugcnutrIQHV/eXv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmIELSemfCsT","executionInfo":{"status":"ok","timestamp":1748529723543,"user_tz":-120,"elapsed":24279,"user":{"displayName":"Thesis Bats","userId":"13415237238781601803"}},"outputId":"e288af35-9d17-4fac-d2ea-1d3296529bf3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/LOOCV_2models_withmasks/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT.zip /content\n","!unzip /content/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT.zip -d /content > /dev/null"],"metadata":{"id":"_pd6UtLpfIp8","executionInfo":{"status":"ok","timestamp":1748529738053,"user_tz":-120,"elapsed":14505,"user":{"displayName":"Thesis Bats","userId":"13415237238781601803"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["```markdown\n","# -----------------------------------------------------------------------------\n","# Script Structure Overview\n","# -----------------------------------------------------------------------------\n","# 1. Configuration: Import modules, define paths, set random seed, and list candidate gÃ®tes.\n","# 2. Held-out Selection: Randomly choose one gÃ®te for validation to ensure reproducibility.\n","# 3. Directory Preparation: Discover classes and create corresponding validation subdirectories.\n","# 4. File Movement Function: Encapsulate logic to move images and masks for a specific class.\n","# 5. Execution Loop: Iterate over all classes, move matching files, and report counts.\n","# 6. Summary: Print the total number of moved pairs, indicating completion of the split.\n","```"],"metadata":{"id":"16vFSD34kLe7"}},{"cell_type":"code","source":["import os\n","import random\n","import shutil\n","\n","# -----------------------------------------------------------------------------\n","# Configuration\n","# -----------------------------------------------------------------------------\n","# Define the base directory containing training and validation data subfolders.\n","base_path = \"/content/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT\"\n","train_img_dir = os.path.join(base_path, \"train_images\")  # Path to training images\n","train_mask_dir = os.path.join(base_path, \"train_masks\")   # Path to training masks\n","val_img_dir = os.path.join(base_path, \"val_images\")      # Destination for validation images\n","val_mask_dir = os.path.join(base_path, \"val_masks\")     # Destination for validation masks\n","\n","# Set a fixed random seed to ensure reproducibility of the held-out selection.\n","RANDOM_SEED = 42\n","random.seed(RANDOM_SEED)\n","\n","# List of candidate gÃ®te identifiers. One will be randomly selected for validation.\n","chosen_gites = [\n","    'Pont_de_Bousval_Photos_2022_PHOTO',\n","    'Modave_Camera_3_toiture_PHOTO',\n","    'Bornival_PHOTO_2023CAM04',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_WK6HDBOUSVAL',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_2022CAM12',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_2023CAM06',\n","    'Bornival_PHOTO_2023CAM03',\n","    'Chaumont_Gistoux_Camera_2',\n","    'Chaumont_Gistoux_Camera_1',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_2023CAM05',\n","    'Jenneret_Camera_1_PHOTO',\n","    'Modave_Camera_plancher_PHOTO'\n","]\n","\n","# Randomly choose one gÃ®te to hold out for the validation set.\n","held_out_gite = random.choice(chosen_gites)\n","print(f\"Holding out gÃ®te for validation: {held_out_gite}\")\n","print(f\"Reproducible with seed: {RANDOM_SEED}\")\n","\n","# -----------------------------------------------------------------------------\n","# Prepare validation directories per class\n","# -----------------------------------------------------------------------------\n","# Identify classes by listing subdirectories in the training image directory.\n","classes = [d for d in os.listdir(train_img_dir)\n","           if os.path.isdir(os.path.join(train_img_dir, d))]\n","\n","# Ensure the base validation directories exist.\n","os.makedirs(val_img_dir, exist_ok=True)\n","os.makedirs(val_mask_dir, exist_ok=True)\n","\n","# Create class-specific subdirectories inside the validation folders.\n","for cls in classes:\n","    os.makedirs(os.path.join(val_img_dir, cls), exist_ok=True)\n","    os.makedirs(os.path.join(val_mask_dir, cls), exist_ok=True)\n","\n","\n","def move_class_images_and_masks(cls, gite_name):\n","    \"\"\"\n","    Move all images and their corresponding masks belonging to a specific class\n","    and matching the held-out gÃ®te identifier into the validation directories.\n","\n","    Args:\n","        cls (str): Name of the class subdirectory.\n","        gite_name (str): Identifier of the held-out gÃ®te to match in filenames.\n","\n","    Returns:\n","        int: Number of image-mask pairs successfully moved.\n","    \"\"\"\n","    src_img_cls = os.path.join(train_img_dir, cls)\n","    src_mask_cls = os.path.join(train_mask_dir, cls)\n","    dst_img_cls = os.path.join(val_img_dir, cls)\n","    dst_mask_cls = os.path.join(val_mask_dir, cls)\n","    moved = 0\n","\n","    for fname in sorted(os.listdir(src_img_cls)):\n","        if gite_name in fname:\n","            img_src = os.path.join(src_img_cls, fname)\n","            base, _ = os.path.splitext(fname)\n","            mask_name = f\"{base}_mask.png\"\n","            mask_src = os.path.join(src_mask_cls, mask_name)\n","\n","            if os.path.exists(mask_src):\n","                # Move both image and mask to the validation directory\n","                shutil.move(img_src, os.path.join(dst_img_cls, fname))\n","                shutil.move(mask_src, os.path.join(dst_mask_cls, mask_name))\n","                moved += 1\n","            else:\n","                # Warn if a mask is expected but missing\n","                print(f\"Warning: Mask not found for {cls} image: {fname}\")\n","\n","    return moved\n","\n","# -----------------------------------------------------------------------------\n","# Execution: Move files for all classes and report summary\n","# -----------------------------------------------------------------------------\n","total_moved = 0\n","for cls in classes:\n","    moved_count = move_class_images_and_masks(cls, held_out_gite)\n","    print(f\"Class '{cls}': moved {moved_count} image-mask pairs\")\n","    total_moved += moved_count\n","\n","print(f\"Total moved {total_moved} image-mask pairs to validation.\")\n"],"metadata":{"id":"UGdiSSfOfJgh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LOO CV Masked-Bat Classifier (EfficientNet-B0 Setup)\n","\n","This repository implements a **leave-one-out cross-validation (LOO CV)** pipeline to train and evaluate a binary image classifier that distinguishes bats from background. It uses masked inputs, data augmentations with MixUp/CutMix, a custom focal loss, and a partially frozen EfficientNet-B0 backbone.\n","\n","---\n","\n","## Features\n","\n","- **Leave-one-out cross-validation** for robust evaluation on small datasets  \n","- **Masked inputs**: per-image binary masks to isolate foreground  \n","- **Data augmentations**: random crop, flip, rotation, color jitter, perspective, blur, erasing  \n","- **MixUp/CutMix** for enhanced generalization  \n","- **Custom Focal Loss** to address class imbalance  \n","- **Partial freezing** of EfficientNet-B0 feature blocks for efficient transfer learning  \n","- **Automatic threshold selection** via precisionâ€“recall curve  \n","- **ROC curve plotting** and AUC computation  \n","- **End-to-end inference** with mask application and decision threshold  \n","\n","---\n","\n","## Directory Structure\n","\n","```\n","/content/loo_temp_<site>_<camera>Camera<fold>/\n","â”œâ”€â”€ train_images/\n","â”‚   â”œâ”€â”€ background/\n","â”‚   â””â”€â”€ bats/\n","â”œâ”€â”€ train_masks/\n","â”‚   â”œâ”€â”€ background/\n","â”‚   â””â”€â”€ bats/\n","â”œâ”€â”€ val_images/\n","â”‚   â”œâ”€â”€ background/\n","â”‚   â””â”€â”€ bats/\n","â”œâ”€â”€ val_masks/\n","â”‚   â”œâ”€â”€ background/\n","â”‚   â””â”€â”€ bats/\n","â”œâ”€â”€ test_images/\n","â”‚   â”œâ”€â”€ background/\n","â”‚   â””â”€â”€ bats/\n","â””â”€â”€ test_masks/\n","    â”œâ”€â”€ background/\n","    â””â”€â”€ bats/\n","```\n","Note:\n","Each image in `*_images/` must have a corresponding mask in `*_masks/` named `<image_basename>_mask.png`. Folders are organized by class (`background` / `bats`).\n","\n","## Key Components\n","\n","1. **Configuration**  \n","   - Define dataset directories, output paths, random seed, batch size, number of epochs, and learning rate  \n","   - Set up device (GPU/CPU), mixed-precision (AMP), and reproducibility  \n","\n","2. **Transforms & Augmentation**  \n","   - **Image Transforms**  \n","     - `RandomResizedCrop(224)`, `RandomHorizontalFlip`, `RandomRotation(15)`  \n","     - `ColorJitter`, `RandomPerspective`, `GaussianBlur`, `RandomErasing`  \n","     - Normalize to ImageNet mean/std  \n","   - **Mask Transforms**  \n","     - Resize to 224Ã—224 (nearest neighbour)  \n","     - Binarize mask to `[0, 1]`  \n","   - **MixUp/CutMix**  \n","     - Batch-level mixing with configurable Î± parameters  \n","\n","3. **Dataset Class**  \n","   - **`MaskedImageDataset`**  \n","     - Loads image and mask pairs, applies transforms, multiplies image by mask  \n","     - Returns `(masked_image, label)`  \n","\n","4. **Data Splits & Loaders**  \n","   - **Training**: Balanced sampling via `WeightedRandomSampler`, data prefetching  \n","   - **Validation/Test**: Sequential loading, larger batch size  \n","\n","5. **Loss Function**  \n","   - **Focal Loss**  \n","     - Î± = `[0.05, 0.95]`, Î³ = `2.0`  \n","     - Emphasizes hard examples, down-weights easy ones  \n","\n","6. **Model & Freezing**  \n","   - Pretrained **EfficientNet-B0** backbone  \n","   - Freeze first two-thirds of feature blocks to retain pretrained representations  \n","   - Replace classifier head with `Dropout(0.5) â†’ Linear(in_features â†’ 2)`  \n","   - Optionally wrap in `torch.compile()` for PyTorch â‰¥ 2.0  \n","\n","7. **Optimizer & Scheduler**  \n","   - **Optimizer**: `AdamW`, learning rate = `3 Ã— 10â»âµ`  \n","   - **Scheduler**: `CosineAnnealingLR` over total training steps  \n","\n","8. **Training & Validation Loop**  \n","   - **Training**  \n","     - Mixed precision (`autocast`, `GradScaler`)  \n","     - Apply MixUp/CutMix  \n","     - Forward/backward pass, optimizer step, scheduler step  \n","   - **Validation**  \n","     - Forward only  \n","     - Compute validation loss and macro F1  \n","   - **Early Stopping**  \n","     - Stop if no F1 improvement for 3 consecutive epochs  \n","   - **Checkpointing**  \n","     - Save best model weights and validation logits/labels  \n","\n","9. **Threshold Optimization & ROC Analysis**  \n","   - Load saved validation logits and labels  \n","   - Compute precisionâ€“recall curve; select threshold where precision â‰ˆ recall  \n","   - Compute ROC curve and AUC; plot with threshold marker  \n","\n","10. **Inference on Test Set**  \n","    - Reload best model and optimal threshold  \n","    - For each test image:  \n","      1. Apply mask (if available)  \n","      2. Forward pass â†’ probability of â€œbatâ€  \n","      3. Apply threshold â†’ predict â€œbatsâ€ vs â€œbackgroundâ€  \n","      4. Log filename, predicted class, probability, mask usage  \n","\n","11. **Final Evaluation**  \n","    - Aggregate test logits and labels  \n","    - Compute precision, recall, macro F1, ROC AUC  \n","    - Print classification report (per-class metrics)  \n","    - Plot final ROC curve for test set  \n","\n","## Hardware Requirements\n","\n","- **GPU** recommended (e.g., NVIDIA T4 on Colab) for mixed precision  \n","- Falls back to CPU if no CUDA device is available  \n","\n","## Outputs\n","\n","- `best.pth`: Checkpoint with highest validation F1  \n","- `blob.pt`: Validation logits & labels for threshold tuning  \n","- `thr.txt`: Selected optimal threshold value  \n","- Inline ROC plots for validation and test phases  \n","\n","## Usage Notes\n","\n","- Adjust `NUM_EPOCHS`, `BATCH_SIZE`, and `LEARNING_RATE` to match dataset size and hardware  \n","- Ensure mask files are correctly named and binary  \n","- For full LOO CV, wrap script in an outer loop over folds  \n","- Enable `torch.compile()` on PyTorch â‰¥ 2.0 for additional speed gains  "],"metadata":{"id":"2xXGwhdDjOb_"}},{"cell_type":"code","source":["\"\"\"\n","Loo CV masked-bat classifier with train/val/test splits, augmentations, MixUp/CutMix,\n","FocalLoss, EfficientNet-B0 head freezing, and inference.\n","\"\"\"\n","import os\n","import random\n","import shutil\n","from collections import Counter\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","from torchvision import transforms\n","from torchvision.transforms import InterpolationMode\n","from PIL import Image\n","from tqdm.auto import tqdm\n","from timm.data.mixup import Mixup\n","from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torch.cuda.amp import autocast, GradScaler\n","from sklearn.metrics import (\n","    precision_score, recall_score, f1_score,\n","    precision_recall_curve, roc_curve, auc,\n","    classification_report\n",")\n","import matplotlib.pyplot as plt\n","\n","# --------------------------\n","# CONFIGURATION\n","# --------------------------\n","DATA_DIR       = \"/content/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT\"\n","TRAIN_IMG_DIR  = os.path.join(DATA_DIR, \"train_images\")\n","TRAIN_MASK_DIR = os.path.join(DATA_DIR, \"train_masks\")\n","VAL_IMG_DIR    = os.path.join(DATA_DIR, \"val_images\")\n","VAL_MASK_DIR   = os.path.join(DATA_DIR, \"val_masks\")\n","TEST_IMG_DIR   = os.path.join(DATA_DIR, \"test_images\")\n","TEST_MASK_DIR  = os.path.join(DATA_DIR, \"test_masks\")\n","\n","\n","# --------------------------\n","# HYPERPARAMS\n","# --------------------------\n","BATCH_SIZE      = 32\n","NUM_EPOCHS      = 10\n","LEARNING_RATE   = 3e-5\n","OUTPUT_DIR      = \"/content/efficientnet_loocv_results\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# --------------------------\n","# DEVICE & AMP\n","# --------------------------\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.backends.cudnn.benchmark = True\n","torch.set_float32_matmul_precision('high')\n","try:\n","    from torch.amp import autocast, GradScaler\n","    AMP_KW = dict(device_type='cuda')\n","except ImportError:\n","    from torch.cuda.amp import autocast, GradScaler\n","    AMP_KW = {}\n","scaler = GradScaler()\n","\n","# --------------------------\n","# TRANSFORMS + MIXUP/CUTMIX\n","# --------------------------\n","weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n","normalize = transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n","\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224, scale=(0.5,1.0), ratio=(0.9,1.1), interpolation=InterpolationMode.BICUBIC),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n","    transforms.RandomPerspective(distortion_scale=0.3, p=0.3),\n","    transforms.GaussianBlur(kernel_size=3, sigma=(0.1,2.0)),\n","    transforms.ToTensor(),\n","    normalize,\n","    transforms.RandomErasing(scale=(0.02,0.2), ratio=(0.3,3.3), p=0.25),\n","])\n","val_transform = transforms.Compose([\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","    normalize,\n","])\n","mask_transform = transforms.Compose([\n","    transforms.Resize((224,224), interpolation=Image.NEAREST),\n","    transforms.ToTensor(),\n","    transforms.Lambda(lambda t: (t>0.5).float()),\n","])\n","mixup_fn = Mixup(\n","    mixup_alpha=0.2, cutmix_alpha=1.0,\n","    prob=0.5, switch_prob=0.5,\n","    mode='batch', label_smoothing=0.0,\n","    num_classes=2\n",")\n","\n","# --------------------------\n","# DATASET\n","# --------------------------\n","class MaskedImageDataset(Dataset):\n","    EXT = {'.jpg','.jpeg','.png','.bmp','.tiff'}\n","    def __init__(self, img_root, mask_root, img_tfm=None, mask_tfm=None):\n","        self.img_root, self.mask_root = img_root, mask_root\n","        self.img_tfm, self.mask_tfm = img_tfm, mask_tfm\n","        self.classes = sorted(d.name for d in os.scandir(img_root) if d.is_dir())\n","        self.cls2idx = {c:i for i,c in enumerate(self.classes)}\n","        self.samples, self.targets = [], []\n","        for c in self.classes:\n","            for fn in os.listdir(os.path.join(img_root, c)):\n","                ext = os.path.splitext(fn)[1].lower()\n","                if ext not in self.EXT: continue\n","                ip = os.path.join(img_root, c, fn)\n","                mp = os.path.join(mask_root, c, os.path.splitext(fn)[0] + '_mask.png')\n","                mp = mp if os.path.isfile(mp) else None\n","                self.samples.append((ip, mp))\n","                self.targets.append(self.cls2idx[c])\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        img_path, mask_path = self.samples[idx]\n","        label = self.targets[idx]\n","\n","        img = Image.open(img_path).convert('RGB')\n","        if self.img_tfm:\n","            img = self.img_tfm(img)\n","\n","        if mask_path:\n","            m = Image.open(mask_path).convert('L')\n","            m = self.mask_tfm(m) if self.mask_tfm else m\n","        else:\n","            m = torch.ones_like(img[:1, :, :])\n","\n","        return img * m, label\n","\n","# --------------------------\n","# DATASPLITS & LOADERS\n","# --------------------------\n","train_set  = MaskedImageDataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, img_tfm=train_transform, mask_tfm=mask_transform)\n","val_set    = MaskedImageDataset(VAL_IMG_DIR,   VAL_MASK_DIR,   img_tfm=val_transform,   mask_tfm=mask_transform)\n","test_set   = MaskedImageDataset(TEST_IMG_DIR,  TEST_MASK_DIR,  img_tfm=val_transform,   mask_tfm=mask_transform)\n","\n","# balanced sampler for training\n","targs = torch.tensor(train_set.targets)\n","cnts  = torch.tensor([Counter(targs.tolist())[i] for i in range(len(train_set.classes))], dtype=torch.float)\n","cls_w = 1. / cnts\n","cls_w /= cls_w.sum()\n","samp_w = cls_w[targs]\n","sampler = WeightedRandomSampler(samp_w, num_samples=len(train_set)*2, replacement=True)\n","\n","num_w = os.cpu_count() or 2\n","train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, sampler=sampler,\n","                          num_workers=num_w, pin_memory=True,\n","                          persistent_workers=True, prefetch_factor=4)\n","val_loader   = DataLoader(val_set,   batch_size=BATCH_SIZE*2, shuffle=False,\n","                          num_workers=num_w, pin_memory=True,\n","                          persistent_workers=True)\n","test_loader  = DataLoader(test_set,  batch_size=BATCH_SIZE*2, shuffle=False,\n","                          num_workers=num_w, pin_memory=True,\n","                          persistent_workers=True)\n","\n","# --------------------------\n","# LOSS\n","# --------------------------\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n","        super().__init__()\n","        self.alpha = torch.tensor(alpha, dtype=torch.float32) if isinstance(alpha,(list,tuple)) else alpha\n","        self.gamma, self.reduction = gamma, reduction\n","    def forward(self, logits, targets):\n","        ce = F.cross_entropy(logits, targets, reduction='none')\n","        pt = torch.exp(-ce)\n","        if isinstance(self.alpha, torch.Tensor):\n","            a = self.alpha.to(logits.device)[targets] if targets.dtype in (torch.int64,torch.int32) else self.alpha.mean()\n","        else: a = self.alpha\n","        loss = a * (1-pt)**self.gamma * ce\n","        return loss.mean() if self.reduction=='mean' else loss.sum()\n","\n","# --------------------------\n","# MODEL + FREEZE\n","# --------------------------\n","# load pretrained EfficientNet-B0\n","weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n","base = efficientnet_b0(weights=weights).to(DEVICE)\n","\n","# freeze first 2/3 of feature blocks\n","features = list(base.features)\n","freeze_upto = int(len(features) * 2 / 3)\n","for i, block in enumerate(features):\n","    if i < freeze_upto:\n","        for p in block.parameters():\n","            p.requires_grad = False\n","\n","# replace classifier head\n","in_feats = base.classifier[1].in_features\n","base.classifier = nn.Sequential(\n","    nn.Dropout(0.5),\n","    nn.Linear(in_feats, 2)\n",").to(DEVICE)\n","\n","try:\n","    model = torch.compile(base)\n","except:\n","    model = base\n","\n","# optimizer & scheduler\n","loss_fn = FocalLoss(alpha=[0.05,0.95], gamma=2.0).to(DEVICE)\n","opt     = AdamW(model.parameters(), lr=LEARNING_RATE)\n","sch     = CosineAnnealingLR(opt, T_max=NUM_EPOCHS * len(train_loader))\n","\n","# --------------------------\n","# TRAIN/VALID LOOP\n","# --------------------------\n","best_f1, noimp, patience = 0.0, 0, 3\n","for epoch in range(1, NUM_EPOCHS + 1):\n","    model.train()\n","    train_loss = 0.0\n","    for x, y in tqdm(train_loader, desc=f\"Train {epoch}/{NUM_EPOCHS}\"):\n","        x, y = x.to(DEVICE), y.to(DEVICE)\n","        x, y = mixup_fn(x, y)\n","        with autocast(**AMP_KW):\n","            logits = model(x)\n","            loss = loss_fn(logits, y)\n","        opt.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(opt)\n","        scaler.update()\n","        sch.step()\n","        train_loss += loss.item()\n","\n","    avg_tr = train_loss / len(train_loader)\n","\n","    # validation\n","    model.eval()\n","    vloss, preds, labs = 0.0, [], []\n","    with torch.no_grad():\n","        for x, y in tqdm(val_loader, desc=\"Valid\"):\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            with autocast(**AMP_KW):\n","                out = model(x)\n","                loss = loss_fn(out, y)\n","            vloss += loss.item()\n","            preds.append(out.cpu())\n","            labs.append(y.cpu())\n","\n","    val_logits = torch.cat(preds)\n","    val_labs   = torch.cat(labs)\n","    avg_val    = vloss / len(val_loader)\n","    f1m        = f1_score(val_labs, val_logits.argmax(dim=1), average='macro')\n","\n","    if f1m > best_f1:\n","        best_f1, noimp = f1m, 0\n","        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'best.pth'))\n","        torch.save({'logits': val_logits, 'labels': val_labs}, os.path.join(OUTPUT_DIR, 'blob.pt'))\n","    else:\n","        noimp += 1\n","        if noimp >= patience:\n","            print(\"Early stop\")\n","            break\n","\n","    print(f\"Epoch {epoch}: TrainL={avg_tr:.4f}, ValL={avg_val:.4f}, F1_macro={f1m:.4f}\")\n","\n","# --------------------------\n","# THRESHOLD & ROC\n","# --------------------------\n","blob = torch.load(os.path.join(OUTPUT_DIR, 'blob.pt'))\n","labels = blob['labels'].numpy()\n","probs  = blob['logits'].softmax(1)[:, 1].numpy()\n","\n","prec, rec, thr = precision_recall_curve(labels, probs)\n","best_thr = thr[np.argmin(np.abs(prec - rec))]\n","with open(os.path.join(OUTPUT_DIR, 'thr.txt'), 'w') as f:\n","    f.write(str(best_thr))\n","\n","fpr, tpr, _ = roc_curve(labels, probs)\n","auc_v = auc(fpr, tpr)\n","\n","plt.figure(figsize=(6,6))\n","plt.plot(fpr, tpr, label=f\"AUC={auc_v:.3f}\")\n","pt = np.argmin(np.abs(_ - best_thr))\n","plt.scatter(fpr[pt], tpr[pt], s=50, label=f\"thr={best_thr:.3f}\")\n","plt.plot([0,1], [0,1], 'k--', alpha=0.4)\n","plt.xlabel(\"FPR\")\n","plt.ylabel(\"TPR\")\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n","# --------------------------\n","# INFERENCE ON TEST\n","# --------------------------\n","print(\"\\nRunning inference on test setâ€¦\")\n","model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, 'best.pth')))\n","model.eval()\n","thr = float(open(os.path.join(OUTPUT_DIR, 'thr.txt')).read())\n","\n","for img_path, mask_path in test_set.samples:\n","    img = Image.open(img_path).convert('RGB')\n","    it  = val_transform(img)\n","    used = ''\n","    if mask_path:\n","        mimg = Image.open(mask_path).convert('L')\n","        mt   = mask_transform(mimg)\n","        it  *= mt\n","        used = '(mask)'\n","\n","    with torch.no_grad(), autocast(**AMP_KW):\n","        lg = model(it.unsqueeze(0).to(DEVICE))\n","    p  = lg.softmax(1)[0,1].item()\n","    pr = 'bats' if p >= thr else 'background'\n","    print(f\"{os.path.basename(img_path)}: {pr} (P={p:.3f}) {used}\")\n","\n","# --------------------------\n","# ðŸ§ª FINAL EVALUATION ON TEST SET\n","# --------------------------\n","print(\"\\nEvaluating on independent TEST setâ€¦\")\n","model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, 'best.pth')))\n","model.eval()\n","\n","test_logits, test_labels = [], []\n","with torch.no_grad():\n","    for x, y in tqdm(test_loader, desc=\"Test\", unit=\"batch\"):\n","        x, y = x.to(DEVICE), y.to(DEVICE)\n","        with autocast(**AMP_KW):\n","            out = model(x)\n","        test_logits.append(out.cpu())\n","        test_labels.append(y.cpu())\n","\n","test_logits = torch.cat(test_logits)\n","test_labels = torch.cat(test_labels)\n","test_probs  = test_logits.softmax(1)[:,1]\n","test_preds  = (test_probs >= best_thr).int()\n","\n","precision = precision_score(test_labels, test_preds, average='macro')\n","recall    = recall_score(test_labels, test_preds, average='macro')\n","f1        = f1_score(test_labels, test_preds, average='macro')\n","fpr, tpr, _ = roc_curve(test_labels, test_probs)\n","roc_auc   = auc(fpr, tpr)\n","\n","print(\n","    f\"\\nðŸ“Š TEST SET PERFORMANCE:\\n\"\n","    f\"Precision: {precision:.4f} â”‚ Recall: {recall:.4f} â”‚ \"\n","    f\"F1_macro: {f1:.4f} â”‚ AUC: {roc_auc:.4f}\"\n",")\n","\n","print(\"\\nClassification Report:\\n\", classification_report(\n","    test_labels, test_preds, target_names=test_set.classes\n","))\n","\n","plt.figure(figsize=(6,6))\n","plt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.3f}\")\n","plt.plot([0,1], [0,1], 'k--', alpha=0.3)\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve - TEST set\")\n","plt.legend(loc=\"lower right\")\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"9WtUPuS6fK46"},"execution_count":null,"outputs":[]}]}