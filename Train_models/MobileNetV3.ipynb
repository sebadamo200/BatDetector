{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2zgKhttORHv-","outputId":"91ececeb-d1e3-4c28-be19-40fd444440f1","executionInfo":{"status":"ok","timestamp":1748531587930,"user_tz":-120,"elapsed":15476,"user":{"displayName":"Thesis Bats","userId":"13415237238781601803"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uGJ6R7cYR4s_"},"outputs":[],"source":["!cp /content/drive/MyDrive/LOOCV_2models_VIT/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT.zip /content\n","!unzip /content/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT.zip -d /content > /dev/null"]},{"cell_type":"code","source":["import os\n","import random\n","import shutil\n","\n","# Base path\n","base_path = \"/content/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT\"\n","train_dir = os.path.join(base_path, \"train\")\n","val_dir = os.path.join(base_path, \"val\")\n","\n","background_dir = os.path.join(train_dir, \"background\")\n","bats_dir = os.path.join(train_dir, \"bats\")\n","\n","val_background_dir = os.path.join(val_dir, \"background\")\n","val_bats_dir = os.path.join(val_dir, \"bats\")\n","\n","# Fixed seed for reproducibility\n","RANDOM_SEED = 42\n","random.seed(RANDOM_SEED)\n","\n","# GÃ®te names\n","chosen_gites = [\n","    'Pont_de_Bousval_Photos_2022_PHOTO',\n","    'Modave_Camera_3_toiture_PHOTO',\n","    'Bornival_PHOTO_2023CAM04',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_WK6HDBOUSVAL',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_2022CAM12',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_2023CAM06',\n","    'Bornival_PHOTO_2023CAM03',\n","    'Chaumont_Gistoux_Camera_2',\n","    'Chaumont_Gistoux_Camera_1',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_2023CAM05',\n","    #'Anthisnes_Chateau_de_Xhos_Camera_1_HIT',\n","    'Jenneret_Camera_1_PHOTO',\n","    'Modave_Camera_plancher_PHOTO'\n","]\n","\n","# Randomly select a gÃ®te using fixed seed\n","held_out_gite = random.choice(chosen_gites)\n","print(f\"ðŸ“¦ Holding out gÃ®te for validation: {held_out_gite}\")\n","print(f\"ðŸ§ª Reproducible with seed: {RANDOM_SEED}\")\n","\n","# Create val folders\n","os.makedirs(val_background_dir, exist_ok=True)\n","os.makedirs(val_bats_dir, exist_ok=True)\n","\n","# Function to move matching files\n","def move_files_by_gite(source_dir, target_dir, gite_name):\n","    moved_count = 0\n","    for fname in sorted(os.listdir(source_dir)):  # sort to ensure order\n","        if gite_name in fname:\n","            shutil.move(os.path.join(source_dir, fname), os.path.join(target_dir, fname))\n","            moved_count += 1\n","    return moved_count\n","\n","# Move files\n","bkg_moved = move_files_by_gite(background_dir, val_background_dir, held_out_gite)\n","bats_moved = move_files_by_gite(bats_dir, val_bats_dir, held_out_gite)\n","\n","print(f\"âœ… Moved {bkg_moved} background images and {bats_moved} bat images to validation set.\")\n"],"metadata":{"id":"xGwxJltclgxW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P-cRZqGeREia"},"outputs":[],"source":["# bat_finetune_mnv3_t4_with_test.py\n","\"\"\"\n","Optimized for Colab T4 GPU, with train/val/test splits and final classification report.\n","Uses the new torch.amp API to avoid deprecation warnings.\n","\"\"\"\n","\n","from pathlib import Path\n","import os\n","import time\n","import random\n","import json\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Subset\n","from torchvision import datasets, transforms as T\n","from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n","from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n","from tqdm import tqdm\n","\n","# ---------- User Configuration ----------\n","DATA_ROOT          = Path(\"/content/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT\")\n","DATA_FRACTION      = 1.0        # fraction of each split to use (0 < fraction â‰¤ 1)\n","EPOCHS             = 25\n","BATCH_SIZE         = 64\n","LEARNING_RATE      = 1e-4\n","FREEZE_RATIO       = 0.6       # fraction of backbone layers to freeze\n","ENABLE_AMP         = True      # automatic mixed precision\n","OUTPUT_DIR         = Path(\"outputs\")\n","NUM_WORKERS        = min(4, os.cpu_count() or 1)\n","PIN_MEMORY         = True\n","PERSISTENT_WORKERS = True\n","PREFETCH_FACTOR    = 2\n","SEED               = 42\n","# ----------------------------------------\n","\n","# reproducibility\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.benchmark = True\n","\n","# prepare output dir\n","OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# device\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {DEVICE}, num_workers={NUM_WORKERS}\")\n","\n","# ImageNet normalization\n","IMG_MEAN = [0.485, 0.456, 0.406]\n","IMG_STD  = [0.229, 0.224, 0.225]\n","\n","# transforms\n","train_tf = T.Compose([\n","    T.RandomHorizontalFlip(),\n","    T.RandomRotation(15),\n","    T.ColorJitter(0.2, 0.2, 0.2),\n","    T.Resize((96, 96)),\n","    T.ToTensor(),\n","    T.Normalize(IMG_MEAN, IMG_STD),\n","])\n","test_tf = T.Compose([\n","    T.Resize((96, 96)),\n","    T.ToTensor(),\n","    T.Normalize(IMG_MEAN, IMG_STD),\n","])\n","\n","# datasets\n","train_ds = datasets.ImageFolder(DATA_ROOT/\"train\", transform=train_tf)\n","val_ds   = datasets.ImageFolder(DATA_ROOT/\"val\",   transform=test_tf)\n","test_ds  = datasets.ImageFolder(DATA_ROOT/\"test\",  transform=test_tf)\n","\n","# optionally subsample\n","def maybe_subsample(ds, frac):\n","    if 0 < frac < 1.0:\n","        n = len(ds)\n","        keep = random.sample(range(n), max(1, int(n*frac)))\n","        return Subset(ds, keep)\n","    return ds\n","\n","train_ds = maybe_subsample(train_ds, DATA_FRACTION)\n","val_ds   = maybe_subsample(val_ds,   DATA_FRACTION)\n","test_ds  = maybe_subsample(test_ds,  DATA_FRACTION)\n","\n","print(f\"â–¶ train: {len(train_ds)} imgs, val: {len(val_ds)} imgs, test: {len(test_ds)} imgs\")\n","\n","# loaders\n","train_loader = DataLoader(\n","    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n","    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n","    persistent_workers=PERSISTENT_WORKERS, prefetch_factor=PREFETCH_FACTOR\n",")\n","val_loader = DataLoader(\n","    val_ds, batch_size=BATCH_SIZE, shuffle=False,\n","    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n","    persistent_workers=PERSISTENT_WORKERS, prefetch_factor=PREFETCH_FACTOR\n",")\n","test_loader = DataLoader(\n","    test_ds, batch_size=BATCH_SIZE, shuffle=False,\n","    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n","    persistent_workers=PERSISTENT_WORKERS, prefetch_factor=PREFETCH_FACTOR\n",")\n","\n","# model setup\n","weights = MobileNet_V3_Small_Weights.IMAGENET1K_V1\n","model = mobilenet_v3_small(weights=weights)\n","num_classes = len(train_ds.dataset.classes) if isinstance(train_ds, Subset) else len(train_ds.classes)\n","in_f = model.classifier[3].in_features\n","model.classifier[3] = nn.Linear(in_f, num_classes)\n","model = model.to(DEVICE)\n","\n","# freeze backbone\n","backbone = [p for n, p in model.named_parameters() if not n.startswith(\"classifier\")]\n","num_freeze = int(len(backbone) * FREEZE_RATIO)\n","for p in backbone[:num_freeze]:\n","    p.requires_grad = False\n","\n","# optimizer / scheduler / loss / AMP scaler\n","optimizer = torch.optim.AdamW(\n","    filter(lambda p: p.requires_grad, model.parameters()),\n","    lr=LEARNING_RATE, weight_decay=1e-4\n",")\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n","criterion = nn.CrossEntropyLoss()\n","\n","from torch import amp\n","scaler = amp.GradScaler() if ENABLE_AMP else None\n","\n","# metrics store\n","best_val_f1 = 0.0\n","history = {\n","    \"train_loss\": [], \"train_acc\": [],\n","    \"val_loss\":   [], \"val_acc\":   [],\n","    \"val_prec\":   [], \"val_rec\":   [], \"val_f1\": []\n","}\n","\n","def compute_acc(logits, y):\n","    return (logits.argmax(1) == y).float().mean().item()\n","\n","# training loop\n","for epoch in range(1, EPOCHS + 1):\n","    t0 = time.time()\n","\n","    # --- train ---\n","    model.train()\n","    running_loss = 0.0; running_acc = 0.0; n_train = 0\n","    for X, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} [Train]\"):\n","        X, y = X.to(DEVICE, non_blocking=True), y.to(DEVICE, non_blocking=True)\n","        optimizer.zero_grad()\n","        if ENABLE_AMP:\n","            with amp.autocast(device_type=DEVICE.type):\n","                logits = model(X)\n","                loss   = criterion(logits, y)\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","        else:\n","            logits = model(X)\n","            loss   = criterion(logits, y)\n","            loss.backward()\n","            optimizer.step()\n","\n","        bs = y.size(0)\n","        running_loss += loss.item() * bs\n","        running_acc  += compute_acc(logits, y) * bs\n","        n_train      += bs\n","\n","    # --- validate ---\n","    model.eval()\n","    v_loss = 0.0; v_acc = 0.0; n_val = 0\n","    all_preds, all_targs = [], []\n","    with torch.no_grad():\n","        for X, y in tqdm(val_loader, desc=f\"Epoch {epoch}/{EPOCHS} [Val]\"):\n","            X, y = X.to(DEVICE, non_blocking=True), y.to(DEVICE, non_blocking=True)\n","            if ENABLE_AMP:\n","                with amp.autocast(device_type=DEVICE.type):\n","                    logits = model(X)\n","            else:\n","                logits = model(X)\n","\n","            loss  = criterion(logits, y)\n","            preds = logits.argmax(1)\n","\n","            v_loss += loss.item() * y.size(0)\n","            v_acc  += (preds == y).sum().item()\n","            n_val  += y.size(0)\n","            all_preds.extend(preds.cpu().tolist())\n","            all_targs.extend(y.cpu().tolist())\n","\n","    tr_loss, tr_acc = running_loss / n_train, running_acc / n_train\n","    val_loss, val_acc = v_loss / n_val, v_acc / n_val\n","    prec = precision_score(all_targs, all_preds, average='binary')\n","    rec  = recall_score(all_targs, all_preds, average='binary')\n","    f1   = f1_score(all_targs, all_preds, average='binary')\n","\n","    history[\"train_loss\"].append(tr_loss)\n","    history[\"train_acc\"].append(tr_acc)\n","    history[\"val_loss\"].append(val_loss)\n","    history[\"val_acc\"].append(val_acc)\n","    history[\"val_prec\"].append(prec)\n","    history[\"val_rec\"].append(rec)\n","    history[\"val_f1\"].append(f1)\n","\n","    print(\n","        f\"[{epoch:02d}/{EPOCHS}] \"\n","        f\"Train loss={tr_loss:.4f}, acc={tr_acc*100:.2f}% | \"\n","        f\"Val loss={val_loss:.4f}, acc={val_acc*100:.2f}% | \"\n","        f\"P={prec*100:.2f}% R={rec*100:.2f}% F1={f1*100:.2f}% | \"\n","        f\"{time.time()-t0:.1f}s\"\n","    )\n","\n","    # save best\n","    if f1 > best_val_f1:\n","        best_val_f1 = f1\n","        ckpt = OUTPUT_DIR / \"best_model.pt\"\n","        torch.jit.script(model.cpu()).save(ckpt)\n","        model.to(DEVICE)\n","        print(f\" â†³ New best model saved ({f1*100:.2f}% F1)\")\n","\n","    scheduler.step()\n","\n","# save final state + history\n","torch.save(model.state_dict(), OUTPUT_DIR / \"last_model.pth\")\n","with open(OUTPUT_DIR / \"history.json\", \"w\") as f:\n","    json.dump(history, f, indent=2)\n","\n","print(f\"\\nTraining done. Best Val F1: {best_val_f1*100:.2f}%\")\n","print(f\"Outputs in {OUTPUT_DIR}/\")\n","\n","# ======= Final evaluation on TEST set =======\n","print(\"\\nEvaluating on TEST set:\")\n","model = torch.jit.load(OUTPUT_DIR / \"best_model.pt\").to(DEVICE)\n","model.eval()\n","\n","all_preds, all_targs = [], []\n","with torch.no_grad():\n","    for X, y in tqdm(test_loader, desc=\"Test Eval\"):\n","        X = X.to(DEVICE, non_blocking=True)\n","        logits = model(X)\n","        preds = logits.argmax(1).cpu().tolist()\n","        all_preds.extend(preds)\n","        all_targs.extend(y.tolist())\n","\n","class_names = train_ds.dataset.classes if isinstance(train_ds, Subset) else train_ds.classes\n","report = classification_report(all_targs, all_preds, target_names=class_names, digits=4)\n","print(report)\n","\n","with open(OUTPUT_DIR / \"classification_report.txt\", \"w\") as f:\n","    f.write(report)\n","\n","print(f\"Test report written to {OUTPUT_DIR}/classification_report.txt\")\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}