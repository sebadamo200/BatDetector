{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMHBYggeFwhOflHZUDaxYaO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Mount Drive & Unzip Dataset  \n","Load Google Drive and extract the dataset."],"metadata":{"id":"VBIgqAjFOrlY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"g_BlzHxxLlIA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748538830341,"user_tz":-120,"elapsed":25581,"user":{"displayName":"Thesis Bats","userId":"13415237238781601803"}},"outputId":"d5580202-33b5-4544-e96c-7c6ab8b006ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/LOOCV_2models_VIT/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT.zip /content\n","!unzip /content/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT.zip -d /content > /dev/null"],"metadata":{"id":"zpmrXGAALrZ4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Select & Hold Out One G√Æte  \n","Randomly choose one site and move its images to validation.\n","\n","## And\n","\n","## Define Paths & Seed  \n","Set up directory paths and a fixed random seed."],"metadata":{"id":"0CAz7TW7O3NX"}},{"cell_type":"markdown","source":["Here‚Äôs the expected directory layout for your dataset:\n","\n","- **train/**: contains two class subfolders  \n","  - **background/** ‚Äì all ‚Äúnegative‚Äù images  \n","  - **bats/**       ‚Äì all ‚Äúpositive‚Äù images  \n","- **val/**: same structure, holds your held-out g√Æte images  \n","- **test/**: same structure, for final evaluation  \n"],"metadata":{"id":"eJg99nMPSdPe"}},{"cell_type":"code","source":["import os\n","import random\n","import shutil\n","\n","# Base path\n","base_path = \"/content/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT\"\n","train_dir = os.path.join(base_path, \"train\")\n","val_dir = os.path.join(base_path, \"val\")\n","\n","background_dir = os.path.join(train_dir, \"background\")\n","bats_dir = os.path.join(train_dir, \"bats\")\n","\n","val_background_dir = os.path.join(val_dir, \"background\")\n","val_bats_dir = os.path.join(val_dir, \"bats\")\n","\n","# Fixed seed for reproducibility\n","RANDOM_SEED = 42\n","random.seed(RANDOM_SEED)\n","\n","# G√Æte names\n","chosen_gites = [\n","    'Pont_de_Bousval_Photos_2022_PHOTO',\n","    'Modave_Camera_3_toiture_PHOTO',\n","    'Bornival_PHOTO_2023CAM04',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_WK6HDBOUSVAL',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_2022CAM12',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_2023CAM06',\n","    'Bornival_PHOTO_2023CAM03',\n","    'Chaumont_Gistoux_Camera_2',\n","    'Chaumont_Gistoux_Camera_1',\n","    'Pont_de_Bousval_Photos_2023_PHOTO_2023CAM05',\n","    #'Anthisnes_Chateau_de_Xhos_Camera_1_HIT',\n","    'Jenneret_Camera_1_PHOTO',\n","    'Modave_Camera_plancher_PHOTO'\n","]\n","\n","# Randomly select a g√Æte using fixed seed\n","held_out_gite = random.choice(chosen_gites)\n","print(f\"üì¶ Holding out g√Æte for validation: {held_out_gite}\")\n","print(f\"üß™ Reproducible with seed: {RANDOM_SEED}\")\n","\n","# Create val folders\n","os.makedirs(val_background_dir, exist_ok=True)\n","os.makedirs(val_bats_dir, exist_ok=True)\n","\n","# Function to move matching files\n","def move_files_by_gite(source_dir, target_dir, gite_name):\n","    moved_count = 0\n","    for fname in sorted(os.listdir(source_dir)):  # sort to ensure order\n","        if gite_name in fname:\n","            shutil.move(os.path.join(source_dir, fname), os.path.join(target_dir, fname))\n","            moved_count += 1\n","    return moved_count\n","\n","# Move files\n","bkg_moved = move_files_by_gite(background_dir, val_background_dir, held_out_gite)\n","bats_moved = move_files_by_gite(bats_dir, val_bats_dir, held_out_gite)\n","\n","print(f\"‚úÖ Moved {bkg_moved} background images and {bats_moved} bat images to validation set.\")\n"],"metadata":{"id":"myqwesJILuuv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748537142753,"user_tz":-120,"elapsed":217,"user":{"displayName":"Thesis Bats","userId":"13415237238781601803"}},"outputId":"461251af-4a68-48f2-9a5f-b193c4d7c9ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üì¶ Holding out g√Æte for validation: Jenneret_Camera_1_PHOTO\n","üß™ Reproducible with seed: 42\n","‚úÖ Moved 6889 background images and 1330 bat images to validation set.\n"]}]},{"cell_type":"markdown","source":["## Imports & Configuration  \n","Import libraries and define training parameters."],"metadata":{"id":"5wMR9uuVOweZ"}},{"cell_type":"code","source":["import math, json, numpy as np, torch\n","from PIL import Image\n","from collections import Counter\n","from tqdm.auto import tqdm\n","from torch.utils.data import DataLoader, WeightedRandomSampler\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n","from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, auc\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.transforms import InterpolationMode\n","from timm.data.mixup import Mixup\n","\n","# Paths & hyperparameters\n","DATA_DIR      = base_path\n","TRAIN_DIR     = os.path.join(DATA_DIR, \"train\")\n","VAL_DIR       = os.path.join(DATA_DIR, \"val\")\n","TEST_DIR      = os.path.join(DATA_DIR, \"test\")\n","INFER_DIR     = TEST_DIR\n","BATCH_SIZE    = 32\n","NUM_EPOCHS    = 1\n","LEARNING_RATE = 3e-5\n","OUTPUT_DIR    = \"/content/efficientnet_finetuned_bats\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.backends.cudnn.benchmark = True\n","torch.set_float32_matmul_precision(\"high\")\n","\n","# Mixed precision setup\n","from torch.cuda.amp import autocast, GradScaler\n","AMP_KW = dict(device_type=\"cuda\")\n","scaler = GradScaler()\n","\n","# Seed everything\n","seed = 42\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","torch.backends.cudnn.deterministic = True"],"metadata":{"id":"DEKKlxJrN7N9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Augmentation & Mixup  \n","Specify train/validation transforms and MixUp augmentation."],"metadata":{"id":"91oJKGOrPHKE"}},{"cell_type":"code","source":["weights   = EfficientNet_B0_Weights.IMAGENET1K_V1\n","normalize = transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n","\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224, scale=(0.5,1.0), ratio=(0.9,1.1), interpolation=InterpolationMode.BICUBIC),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n","    transforms.RandomPerspective(0.3, p=0.3),\n","    transforms.GaussianBlur(3, sigma=(0.1,2.0)),\n","    transforms.ToTensor(),\n","    normalize,\n","    transforms.RandomErasing(scale=(0.02,0.2), ratio=(0.3,3.3), p=0.25),\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","    normalize,\n","])\n","\n","mixup_fn = Mixup(\n","    num_classes=2, mixup_alpha=0.2, cutmix_alpha=1.0,\n","    prob=1.0, switch_prob=0.5, mode=\"batch\", label_smoothing=0.0\n",")\n"],"metadata":{"id":"bU1HuWKBOBMF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Focal Loss Definition  \n","Implement a drop-in Focal Loss module.\n"],"metadata":{"id":"DdL3AJQZPJDk"}},{"cell_type":"code","source":["class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2.0, reduction=\"mean\"):\n","        super().__init__()\n","        self.alpha = torch.tensor(alpha) if isinstance(alpha, (list, tuple)) else alpha\n","        self.gamma, self.reduction = gamma, reduction\n","\n","    def forward(self, logits, targets):\n","        ce = F.cross_entropy(logits, targets, reduction=\"none\")\n","        pt = torch.exp(-ce)\n","        a = self.alpha.to(logits.device)[targets] if isinstance(self.alpha, torch.Tensor) else self.alpha\n","        loss = a * (1 - pt) ** self.gamma * ce\n","        return loss.mean() if self.reduction==\"mean\" else loss.sum()\n"],"metadata":{"id":"2_A4ELd-OFVk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Setup  \n","Load EfficientNet-B0, freeze early layers, and replace the classifier.\n"],"metadata":{"id":"HATG-lAxPab2"}},{"cell_type":"code","source":["base_model = efficientnet_b0(weights=weights)\n","freeze_upto = len(base_model.features) * 2 // 3\n","for i, block in enumerate(base_model.features):\n","    if i < freeze_upto:\n","        for p in block.parameters():\n","            p.requires_grad = False\n","\n","base_model.classifier = nn.Sequential(\n","    nn.Dropout(0.5),\n","    nn.Linear(base_model.classifier[1].in_features, 2)\n",")\n","\n","try:\n","    model = torch.compile(base_model.to(DEVICE))\n","except:\n","    model = base_model.to(DEVICE)\n"],"metadata":{"id":"hbFAxP3jOUWS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Optimizer & Scheduler  \n","Configure loss, optimizer, and learning-rate schedule.\n"],"metadata":{"id":"z9xr-ZvLPdyy"}},{"cell_type":"code","source":["alpha     = torch.tensor([0.05, 0.95])\n","loss_fn   = FocalLoss(alpha=alpha, gamma=2.0).to(DEVICE)\n","optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n","scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS * len(train_loader))\n"],"metadata":{"id":"ANQdkgdNOX3Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training & Validation Loop  \n","Train for epochs, track metrics, and save the best model.\n"],"metadata":{"id":"2v0VJHwXPffa"}},{"cell_type":"code","source":["best_f1, patience, epochs_no_imp = 0.0, 3, 0\n","\n","for epoch in range(1, NUM_EPOCHS+1):\n","    model.train()\n","    total_train = 0\n","    for x, y in tqdm(train_loader, desc=f\"Train {epoch}/{NUM_EPOCHS}\"):\n","        x, y = x.to(DEVICE), y.to(DEVICE)\n","        x, y = mixup_fn(x, y)\n","        with autocast(**AMP_KW):\n","            logits = model(x)\n","            loss   = loss_fn(logits, y)\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        scheduler.step()\n","        total_train += loss.item()\n","    avg_train = total_train / len(train_loader)\n","\n","    model.eval()\n","    val_losses, all_logits, all_labels = 0.0, [], []\n","    with torch.no_grad():\n","        for x, y in tqdm(val_loader, desc=\"Valid\", leave=False):\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            with autocast(**AMP_KW):\n","                out  = model(x)\n","                loss = loss_fn(out, y)\n","            val_losses += loss.item()\n","            all_logits.append(out.cpu())\n","            all_labels.append(y.cpu())\n","    avg_val = val_losses / len(val_loader)\n","\n","    logits  = torch.cat(all_logits)\n","    labels  = torch.cat(all_labels)\n","    preds   = logits.argmax(1)\n","    f1_m    = f1_score(labels, preds, average=\"macro\")\n","\n","    print(f\"Epoch {epoch}: TrainL={avg_train:.4f} ValL={avg_val:.4f} F1={f1_m:.4f}\")\n","\n","    if f1_m > best_f1:\n","        best_f1, epochs_no_imp = f1_m, 0\n","        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"best_model.pth\"))\n","        torch.save({\"logits\": logits, \"labels\": labels},   os.path.join(OUTPUT_DIR, \"val_blob.pt\"))\n","    else:\n","        epochs_no_imp += 1\n","        if epochs_no_imp >= patience:\n","            print(\"Early stopping.\")\n","            break\n"],"metadata":{"id":"3dX9dCKtOYHz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Threshold Tuning & ROC  \n","Find the optimal decision threshold and plot the ROC curve.\n"],"metadata":{"id":"MDN2sVMpPleU"}},{"cell_type":"code","source":["blob   = torch.load(os.path.join(OUTPUT_DIR, \"val_blob.pt\"))\n","labels = blob[\"labels\"].numpy()\n","probs  = blob[\"logits\"].softmax(1)[:,1].numpy()\n","\n","prec, rec, thr = precision_recall_curve(labels, probs)\n","best_thr = thr[np.argmin(np.abs(prec-rec))]\n","with open(os.path.join(OUTPUT_DIR, \"best_thr.txt\"), \"w\") as f:\n","    f.write(f\"{best_thr:.4f}\")\n","\n","fpr, tpr, roc_thr = roc_curve(labels, probs)\n","roc_auc = auc(fpr, tpr)\n","idx     = np.argmin(np.abs(roc_thr-best_thr))\n","\n","plt.figure(figsize=(6,6))\n","plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n","plt.scatter(fpr[idx], tpr[idx], s=60, label=f\"Thr={best_thr:.3f}\")\n","plt.plot([0,1],[0,1],\"k--\",alpha=0.4)\n","plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n","plt.title(\"ROC Curve\"); plt.legend(loc=\"lower right\")\n","plt.grid(True); plt.tight_layout(); plt.show()\n"],"metadata":{"id":"aEb2V9O5OZYq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Inference on Test Crops  \n","Run the trained model on test images.\n"],"metadata":{"id":"LutS6Yx3Pocs"}},{"cell_type":"code","source":["model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, \"best_model.pth\")))\n","model.eval()\n","best_thr = float(open(os.path.join(OUTPUT_DIR, \"best_thr.txt\")).read())\n","\n","for fn in os.listdir(INFER_DIR):\n","    if not fn.lower().endswith((\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tiff\")):\n","        continue\n","    img    = Image.open(os.path.join(INFER_DIR, fn)).convert(\"RGB\")\n","    tensor = val_transform(img).unsqueeze(0).to(DEVICE)\n","    with torch.no_grad(), autocast(**AMP_KW):\n","        prob = model(tensor).softmax(1)[0,1].item()\n","    pred = \"bats\" if prob >= best_thr else \"background\"\n","    print(f\"{fn}: {pred} (Pbat={prob:.3f})\")\n"],"metadata":{"id":"QevIbez1OdVL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","## Final Test Evaluation  \n","Evaluate on the independent test set and report metrics."],"metadata":{"id":"8R5k2EgKPqnL"}},{"cell_type":"code","source":["test_set    = ImageFolder(TEST_DIR, transform=val_transform)\n","test_loader = DataLoader(test_set, batch_size=BATCH_SIZE*2, shuffle=False,\n","                         num_workers=num_workers, pin_memory=True,\n","                         persistent_workers=True)\n","\n","all_logits, all_labels = [], []\n","with torch.no_grad():\n","    for x, y in tqdm(test_loader, desc=\"Test\", leave=False):\n","        x, y = x.to(DEVICE), y.to(DEVICE)\n","        out  = model(x)\n","        all_logits.append(out.cpu())\n","        all_labels.append(y.cpu())\n","\n","logits = torch.cat(all_logits); labels = torch.cat(all_labels)\n","probs  = logits.softmax(1)[:,1]\n","preds  = (probs >= best_thr).int()\n","\n","precision = precision_score(labels, prefs, average=\"macro\")\n","recall    = recall_score(labels, preds, average=\"macro\")\n","f1_score  = f1_score(labels, preds, average=\"macro\")\n","fpr, tpr, _ = roc_curve(labels, probs)\n","roc_auc    = auc(fpr, tpr)\n","\n","print(f\"Test precision={precision:.4f} recall={recall:.4f} F1={f1_score:.4f} AUC={roc_auc:.4f}\")\n","plt.figure(figsize=(6,6))\n","plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n","plt.plot([0,1],[0,1],'k--',alpha=0.3)\n","plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n","plt.title(\"ROC - Test Set\"); plt.legend(loc=\"lower right\")\n","plt.grid(True); plt.tight_layout(); plt.show()\n"],"metadata":{"id":"o6WX-uUSOfUq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EfficientNet-B0 Bat Classifier (Google Colab Setup)\n","\n","This script trains and evaluates a binary image classifier to distinguish bats from background images using EfficientNet-B0.\n","\n","## Features\n","- Mixed-precision training using `torch.amp.autocast` for speed and efficiency\n","- `torch.compile()` for accelerated model execution (when supported)\n","- Balanced sampling and MixUp/CutMix augmentations for robust training\n","- Drop-in Focal Loss implementation to handle class imbalance\n","- Automatic threshold tuning with ROC/PR curve analysis\n","- Final performance metrics and visualization (AUC, F1, Precision, Recall)\n","\n","## Directory Structure\n","\n","```\n","/content/loo_temp_<dataset_name>/\n","‚îú‚îÄ‚îÄ train/\n","‚îÇ   ‚îú‚îÄ‚îÄ background/\n","‚îÇ   ‚îî‚îÄ‚îÄ bats/\n","‚îú‚îÄ‚îÄ val/\n","‚îÇ   ‚îú‚îÄ‚îÄ background/\n","‚îÇ   ‚îî‚îÄ‚îÄ bats/\n","‚îî‚îÄ‚îÄ test/\n","    ‚îú‚îÄ‚îÄ background/\n","    ‚îî‚îÄ‚îÄ bats/\n","```\n","\n","Each folder should contain image files named with identifiable g√Æte prefixes (e.g. `Jenneret_Camera_1_PHOTO_img123.jpg`).\n","\n","---\n","\n","## Key Modules\n","\n","### Configuration\n","- Sets paths, batch size, learning rate, device, and seeds for reproducibility.\n","\n","### Transforms and Augmentation\n","- Applies standard resizing and normalization.\n","- Augmentation includes rotation, jitter, perspective, and Gaussian blur.\n","- MixUp and CutMix are applied in training mode.\n","\n","### Data Handling\n","- Uses `ImageFolder` for dataset loading.\n","- Implements weighted sampling to balance classes in training.\n","\n","### Model Architecture\n","- Uses pretrained `efficientnet_b0` from `torchvision`.\n","- Freezes early layers (2/3) and customizes the classification head.\n","\n","### Loss Function\n","- Implements a configurable Focal Loss to reduce the impact of easy negatives.\n","\n","### Training Loop\n","- Supports early stopping based on F1 score improvements on validation data.\n","- Trains with `GradScaler` for AMP and schedules learning rate with cosine annealing.\n","\n","### Threshold Optimization\n","- Automatically selects the decision threshold where precision ‚âà recall.\n","- Saves optimal threshold and visualizes the ROC curve.\n","\n","### Inference\n","- Loads the best-performing model.\n","- Applies threshold to test/inference images and prints classification results.\n","\n","### Final Evaluation\n","- Computes and prints macro-averaged precision, recall, F1, and AUC on test set.\n","- Plots ROC curve for test data.\n","\n","---\n","\n","## Hardware Requirements\n","- Designed for use on Google Colab with an NVIDIA T4 GPU.\n","- Can fallback to CPU if GPU is unavailable.\n","\n","---\n","\n","## Outputs\n","- `best_model.pth`: Saved weights of the best-performing model.\n","- `val_blob.pt`: Cached validation logits and labels.\n","- `best_thr.txt`: Optimal threshold for bat classification.\n","- ROC plots displayed inline via `matplotlib`.\n","\n","---\n","\n","## Notes\n","- Ensure your dataset is pre-structured before training.\n","- Adjust `NUM_EPOCHS`, `BATCH_SIZE`, or learning rate as needed for larger datasets.\n","- This script is modular and can be adapted to other binary classification tasks with minimal changes.\n"],"metadata":{"id":"3jmP_LoDTKLA"}},{"cell_type":"code","source":["# ===========================  bat_classifier.py (EfficientNet version)  ===========================\n","\"\"\"\n","EfficientNet-B0 bat / background classifier\n","‚Ä¢ Mixed-precision via torch.amp.autocast  (no deprecation warnings)\n","‚Ä¢ torch.compile(), fast DataLoader, in-file Focal-Loss\n","‚Ä¢ Tuned for Google-Colab‚Äôs NVIDIA T4\n","\"\"\"\n","\n","import os\n","import random\n","import json\n","import math\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.datasets import ImageFolder\n","\n","from PIL import Image\n","from collections import Counter\n","from tqdm.auto import tqdm\n","\n","from torch.utils.data import DataLoader, WeightedRandomSampler\n","from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","\n","from sklearn.metrics import (\n","    precision_score, recall_score, f1_score,\n","    precision_recall_curve, roc_curve, auc\n",")\n","\n","import matplotlib.pyplot as plt\n","\n","from timm.data.mixup import Mixup\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","# ‚îÄ‚îÄ Reproducibility ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark     = True\n","torch.set_float32_matmul_precision(\"high\")\n","\n","# ‚îÄ‚îÄ Config ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","DATA_DIR      = \"/content/loo_temp_Anthisnes_Chateau_de_Xhos_Camera_1_HIT\"\n","TRAIN_DIR     = os.path.join(DATA_DIR, \"train\")\n","VAL_DIR       = os.path.join(DATA_DIR, \"val\")\n","TEST_DIR      = os.path.join(DATA_DIR, \"test\")\n","INFER_DIR     = TEST_DIR\n","\n","OUTPUT_DIR    = \"/content/efficientnet_finetuned_bats_Anthisnes_Chateau_de_Xhos_Camera_1_HIT\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","BATCH_SIZE    = 32\n","NUM_EPOCHS    = 1\n","LEARNING_RATE = 3e-5\n","IMAGE_SIZE    = 224\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# ‚îÄ‚îÄ AMP Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","try:\n","    from torch.amp import autocast, GradScaler\n","    AMP_KW = dict(device_type=\"cuda\")\n","except ImportError:\n","    from torch.cuda.amp import autocast, GradScaler\n","    AMP_KW = {}\n","scaler = GradScaler()\n","\n","# ‚îÄ‚îÄ MixUp ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","mixup_fn = Mixup(\n","    num_classes=2,\n","    mixup_alpha=0.2,\n","    cutmix_alpha=1.0,\n","    prob=1.0,\n","    switch_prob=0.5,\n","    mode=\"batch\",\n","    label_smoothing=0.0\n",")\n","\n","# ‚îÄ‚îÄ Albumentations pipelines ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","train_albu = A.Compose([\n","    A.RandomResizedCrop(\n","        size=(IMAGE_SIZE, IMAGE_SIZE),   # ‚Üê use `size=` now\n","        scale=(0.5, 1.0),\n","        ratio=(0.9, 1.1),\n","        p=1.0\n","    ),\n","    A.HorizontalFlip(p=0.5),\n","    A.Rotate(limit=15, p=0.3),\n","    A.RandomBrightnessContrast(\n","        brightness_limit=0.2,\n","        contrast_limit=0.2,\n","        p=0.3\n","    ),\n","    A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n","    A.GaussNoise(std_range=(0.04, 0.20), p=0.2),\n","    A.OneOf([\n","        A.MotionBlur(blur_limit=5, p=1.0),\n","        A.MedianBlur(blur_limit=5, p=1.0),\n","        A.Blur(blur_limit=5, p=1.0),\n","    ], p=0.2),\n","    A.CLAHE(p=0.1),\n","    A.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n","    ToTensorV2(),\n","])\n","\n","val_albu = A.Compose([\n","    A.Resize(                       # ‚Üê this is fine, but you can also use `size=`:\n","        height=IMAGE_SIZE, width=IMAGE_SIZE\n","    ),\n","    A.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n","    ToTensorV2(),\n","])\n","\n","# ‚îÄ‚îÄ Dataset wrapper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","class AlbumentationsDataset(torch.utils.data.Dataset):\n","    def __init__(self, folder, albu_transform):\n","        self.ds   = ImageFolder(folder, transform=None)\n","        self.albu = albu_transform\n","\n","    def __len__(self):\n","        return len(self.ds)\n","\n","    def __getitem__(self, idx):\n","        img, lbl = self.ds[idx]\n","        augmented = self.albu(image=np.array(img))\n","        return augmented[\"image\"], lbl\n","\n","# ‚îÄ‚îÄ DataLoaders ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","train_set = AlbumentationsDataset(TRAIN_DIR, train_albu)\n","val_set   = AlbumentationsDataset(VAL_DIR,   val_albu)\n","test_set  = AlbumentationsDataset(TEST_DIR,  val_albu)\n","\n","# compute class‚Äêbalanced sampler for train\n","targets      = train_set.ds.targets\n","class_cnt    = Counter(targets)\n","cnt          = torch.tensor([class_cnt[i] for i in range(len(class_cnt))], dtype=torch.float)\n","class_weights = (1. / cnt)\n","class_weights /= class_weights.sum()\n","sample_weights = class_weights[targets]\n","\n","sampler = WeightedRandomSampler(\n","    sample_weights, num_samples=len(train_set)*2, replacement=True\n",")\n","num_workers = os.cpu_count() or 2\n","\n","train_loader = DataLoader(\n","    train_set, batch_size=BATCH_SIZE, sampler=sampler,\n","    num_workers=num_workers, pin_memory=True,\n","    persistent_workers=True, prefetch_factor=4\n",")\n","val_loader = DataLoader(\n","    val_set,   batch_size=BATCH_SIZE*2, shuffle=False,\n","    num_workers=num_workers, pin_memory=True,\n","    persistent_workers=True\n",")\n","test_loader = DataLoader(\n","    test_set,  batch_size=BATCH_SIZE*2, shuffle=False,\n","    num_workers=num_workers, pin_memory=True,\n","    persistent_workers=True\n",")\n","\n","# ‚îÄ‚îÄ Focal Loss ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2.0, reduction=\"mean\"):\n","        super().__init__()\n","        if isinstance(alpha, (list, tuple)):\n","            alpha = torch.tensor(alpha, dtype=torch.float32)\n","        self.alpha, self.gamma, self.reduction = alpha, gamma, reduction\n","\n","    def forward(self, logits: torch.Tensor, targets: torch.Tensor):\n","        ce = F.cross_entropy(logits, targets, reduction=\"none\")\n","        pt = torch.exp(-ce)\n","\n","        if isinstance(self.alpha, torch.Tensor):\n","            if targets.dtype in (torch.int64, torch.int32):  # hard labels\n","                a = self.alpha.to(logits.device)[targets]\n","            else:  # soft labels\n","                a = self.alpha.mean().to(logits.device)\n","        else:\n","            a = self.alpha\n","\n","        loss = a * (1 - pt) ** self.gamma * ce\n","        return loss.mean() if self.reduction == \"mean\" else loss.sum()\n","\n","# ‚îÄ‚îÄ Model, optimizer, scheduler ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","weights   = EfficientNet_B0_Weights.IMAGENET1K_V1\n","base_model= efficientnet_b0(weights=weights)\n","\n","# freeze early blocks\n","total_blocks = len(base_model.features)\n","freeze_upto  = int(total_blocks * 2 / 3)\n","for i, block in enumerate(base_model.features):\n","    if i < freeze_upto:\n","        for p in block.parameters():\n","            p.requires_grad = False\n","\n","base_model.classifier = nn.Sequential(\n","    nn.Dropout(p=0.5),\n","    nn.Linear(base_model.classifier[1].in_features, 2)\n",")\n","\n","try:\n","    model = torch.compile(base_model.to(DEVICE))\n","except Exception:\n","    model = base_model.to(DEVICE)\n","\n","alpha    = torch.tensor([0.05, 0.95])\n","loss_fn  = FocalLoss(alpha=alpha, gamma=2.0).to(DEVICE)\n","optimizer= AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n","scheduler= CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS * len(train_loader))\n","\n","# ‚îÄ‚îÄ Training & Validation Loop ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","patience, best_f1, epochs_no_imp = 3, 0.0, 0\n","for epoch in range(1, NUM_EPOCHS+1):\n","    model.train()\n","    train_loss = 0.0\n","    for xb, yb in tqdm(train_loader, desc=f\"Train {epoch}/{NUM_EPOCHS}\", unit=\"batch\"):\n","        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n","        xb, yb = mixup_fn(xb, yb)\n","        with autocast(**AMP_KW):\n","            logits = model(xb)\n","            loss   = loss_fn(logits, yb)\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        scheduler.step()\n","        train_loss += loss.item()\n","\n","    avg_train = train_loss / len(train_loader)\n","\n","    model.eval()\n","    val_logits, val_labels, val_loss = [], [], 0.0\n","    with torch.no_grad():\n","        for xb, yb in tqdm(val_loader, desc=\"Valid\", unit=\"batch\", leave=False):\n","            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n","            with autocast(**AMP_KW):\n","                out  = model(xb)\n","                loss = loss_fn(out, yb)\n","            val_loss += loss.item()\n","            val_logits.append(out.cpu())\n","            val_labels.append(yb.cpu())\n","\n","    val_logits = torch.cat(val_logits)\n","    val_labels = torch.cat(val_labels)\n","    avg_val = val_loss / len(val_loader)\n","    preds   = val_logits.argmax(dim=1)\n","\n","    f1_macro = f1_score(val_labels, preds, average=\"macro\")\n","    prec_m   = precision_score(val_labels, preds, average=\"macro\")\n","    rec_m    = recall_score(val_labels, preds, average=\"macro\")\n","\n","    print(\n","        f\"Epoch {epoch:02d} ‚îÇ \"\n","        f\"TrainL {avg_train:.4f} ‚îÇ ValL {avg_val:.4f} ‚îÇ \"\n","        f\"F1_macro {f1_macro:.4f} ‚îÇ Precision {prec_m:.4f} ‚îÇ Recall {rec_m:.4f}\"\n","    )\n","\n","    if f1_macro > best_f1:\n","        best_f1, epochs_no_imp = f1_macro, 0\n","        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"best_model.pth\"))\n","        torch.save({\"logits\": val_logits, \"labels\": val_labels},\n","                   os.path.join(OUTPUT_DIR, \"val_blob.pt\"))\n","    else:\n","        epochs_no_imp += 1\n","        if epochs_no_imp >= patience:\n","            print(\"Early stopping.\")\n","            break\n","\n","# ‚îÄ‚îÄ Threshold & ROC on Validation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","blob   = torch.load(os.path.join(OUTPUT_DIR, \"val_blob.pt\"))\n","labels = blob[\"labels\"].numpy()\n","probs  = blob[\"logits\"].softmax(1)[:,1].numpy()\n","\n","prec, rec, thr   = precision_recall_curve(labels, probs)\n","best_thr         = float(thr[np.argmin(np.abs(prec-rec))])\n","with open(os.path.join(OUTPUT_DIR, \"best_thr.txt\"), \"w\") as f:\n","    f.write(str(best_thr))\n","print(f\"Optimal threshold: {best_thr:.4f}\")\n","\n","fpr, tpr, roc_t  = roc_curve(labels, probs)\n","roc_auc          = auc(fpr, tpr)\n","idx_pt           = np.argmin(np.abs(roc_t - best_thr))\n","fpr_pt, tpr_pt   = fpr[idx_pt], tpr[idx_pt]\n","\n","plt.figure(figsize=(6,6))\n","plt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.3f}\")\n","plt.scatter([fpr_pt], [tpr_pt], c=\"red\", s=60,\n","            label=f\"Thr={best_thr:.3f}\\nFPR={fpr_pt:.3f},TPR={tpr_pt:.3f}\")\n","plt.plot([0,1],[0,1],\"k--\",alpha=0.4)\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC - Validation\")\n","plt.legend(loc=\"lower right\")\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n","# ‚îÄ‚îÄ Inference on Single Crops ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","print(\"\\nInference on crops ‚Ä¶\")\n","model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, \"best_model.pth\")))\n","model.eval()\n","best_thr = float(open(os.path.join(OUTPUT_DIR, \"best_thr.txt\")).read())\n","\n","for fn in os.listdir(INFER_DIR):\n","    if not fn.lower().endswith((\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tiff\")):\n","        continue\n","    img = np.array(Image.open(os.path.join(INFER_DIR, fn)).convert(\"RGB\"))\n","    inp = val_albu(image=img)[\"image\"].unsqueeze(0).to(DEVICE)\n","    with torch.no_grad(), autocast(**AMP_KW):\n","        logit = model(inp)\n","    prob = logit.softmax(1)[0,1].item()\n","    pred = \"bats\" if prob >= best_thr else \"background\"\n","    print(f\"{fn}: {pred} (Pbat={prob:.3f})\")\n","\n","# ‚îÄ‚îÄ Final Evaluation on TEST_SET ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","print(\"\\nEvaluating on TEST_DIR ‚Ä¶\")\n","model.eval()\n","test_logits, test_labels = [], []\n","with torch.no_grad():\n","    for xb, yb in tqdm(test_loader, desc=\"Test\", unit=\"batch\", leave=False):\n","        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n","        with autocast(**AMP_KW):\n","            out = model(xb)\n","        test_logits.append(out.cpu())\n","        test_labels.append(yb.cpu())\n","\n","test_logits = torch.cat(test_logits)\n","test_labels = torch.cat(test_labels)\n","test_probs  = test_logits.softmax(1)[:,1]\n","test_preds  = (test_probs >= best_thr).int()\n","\n","precision = precision_score(test_labels, test_preds, average=\"macro\")\n","recall    = recall_score(test_labels, test_preds, average=\"macro\")\n","f1_score_  = f1_score(test_labels, test_preds, average=\"macro\")\n","fpr, tpr, _= roc_curve(test_labels, test_probs)\n","roc_auc    = auc(fpr, tpr)\n","\n","print(\n","    f\"\\n TEST SET PERFORMANCE:\\n\"\n","    f\"Precision: {precision:.4f} ‚îÇ Recall: {recall:.4f} ‚îÇ \"\n","    f\"F1_macro: {f1_score_:.4f} ‚îÇ AUC: {roc_auc:.4f}\"\n",")\n","\n","plt.figure(figsize=(6,6))\n","plt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.3f}\")\n","plt.plot([0,1],[0,1],'k--',alpha=0.3)\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve - TEST\")\n","plt.legend(loc=\"lower right\")\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"Q73YCF_I6woy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Final Train for end-point model"],"metadata":{"id":"8uBtS4zaz4uU"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_roDQUcs2K5M","executionInfo":{"status":"ok","timestamp":1748542284343,"user_tz":-120,"elapsed":19150,"user":{"displayName":"Thesis Bats","userId":"13415237238781601803"}},"outputId":"ec130188-c797-4b35-c985-638eb33b5b69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/Final_train.zip /content\n","!unzip /content/Final_train.zip -d /content > /dev/null"],"metadata":{"id":"VN5j7Mz32NYm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ===========================  bat_classifier.py (EfficientNet version)  ===========================\n","\"\"\"\n","EfficientNet-B0 bat / background classifier\n","‚Ä¢ Mixed-precision via torch.amp.autocast\n","‚Ä¢ torch.compile(), fast DataLoader, in-file Focal-Loss\n","‚Ä¢ Trained on the entire Final_train dataset\n","\"\"\"\n","\n","import os\n","import random\n","import json\n","import math\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.datasets import ImageFolder\n","\n","from PIL import Image\n","from collections import Counter\n","from tqdm.auto import tqdm\n","\n","from torch.utils.data import DataLoader, WeightedRandomSampler\n","from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","\n","from sklearn.metrics import (\n","    precision_score, recall_score, f1_score,\n","    precision_recall_curve, roc_curve, auc\n",")\n","\n","import matplotlib.pyplot as plt\n","\n","from timm.data.mixup import Mixup\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","# ‚îÄ‚îÄ Reproducibility ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark     = True\n","torch.set_float32_matmul_precision(\"high\")\n","\n","# ‚îÄ‚îÄ Config ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","DATA_DIR   = \"/content/Final_train\"\n","OUTPUT_DIR = \"outputs\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","BATCH_SIZE    = 32\n","NUM_EPOCHS    = 10\n","LEARNING_RATE = 3e-5\n","IMAGE_SIZE    = 224\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# ‚îÄ‚îÄ AMP Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","try:\n","    from torch.amp import autocast, GradScaler\n","    AMP_KW = dict(device_type=\"cuda\")\n","except ImportError:\n","    from torch.cuda.amp import autocast, GradScaler\n","    AMP_KW = {}\n","scaler = GradScaler()\n","\n","# ‚îÄ‚îÄ MixUp ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","mixup_fn = Mixup(\n","    num_classes=2,\n","    mixup_alpha=0.2,\n","    cutmix_alpha=1.0,\n","    prob=1.0,\n","    switch_prob=0.5,\n","    mode=\"batch\",\n","    label_smoothing=0.0\n",")\n","\n","# ‚îÄ‚îÄ Albumentations pipelines ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","train_albu = A.Compose([\n","    A.RandomResizedCrop(size=(IMAGE_SIZE, IMAGE_SIZE), scale=(0.5, 1.0), ratio=(0.9, 1.1), p=1.0),\n","    A.HorizontalFlip(p=0.5),\n","    A.Rotate(limit=15, p=0.3),\n","    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),\n","    A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n","    A.GaussNoise(std_range=(0.04, 0.20), p=0.2),\n","    A.OneOf([\n","        A.MotionBlur(blur_limit=5, p=1.0),\n","        A.MedianBlur(blur_limit=5, p=1.0),\n","        A.Blur(blur_limit=5, p=1.0),\n","    ], p=0.2),\n","    A.CLAHE(p=0.1),\n","    A.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n","    ToTensorV2(),\n","])\n","\n","# ‚îÄ‚îÄ Dataset wrapper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","class AlbumentationsDataset(torch.utils.data.Dataset):\n","    def __init__(self, folder, albu_transform):\n","        self.ds   = ImageFolder(folder, transform=None)\n","        self.albu = albu_transform\n","\n","    def __len__(self):\n","        return len(self.ds)\n","\n","    def __getitem__(self, idx):\n","        img, lbl = self.ds[idx]\n","        augmented = self.albu(image=np.array(img))\n","        return augmented[\"image\"], lbl\n","\n","# ‚îÄ‚îÄ DataLoader ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","train_set = AlbumentationsDataset(TRAIN_DIR, train_albu)\n","\n","# compute class‚Äêbalanced sampler\n","targets       = train_set.ds.targets\n","class_cnt     = Counter(targets)\n","cnt           = torch.tensor([class_cnt[i] for i in range(len(class_cnt))], dtype=torch.float)\n","class_weights = (1. / cnt)\n","class_weights /= class_weights.sum()\n","sample_weights = class_weights[targets]\n","\n","sampler = WeightedRandomSampler(\n","    sample_weights, num_samples=len(train_set), replacement=True\n",")\n","\n","num_workers = os.cpu_count() or 2\n","train_loader = DataLoader(\n","    train_set, batch_size=BATCH_SIZE, sampler=sampler,\n","    num_workers=num_workers, pin_memory=True,\n","    persistent_workers=True, prefetch_factor=4,\n","    drop_last=True,\n",")\n","# ‚îÄ‚îÄ Focal Loss ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2.0, reduction=\"mean\"):\n","        super().__init__()\n","        if isinstance(alpha, (list, tuple)):\n","            alpha = torch.tensor(alpha, dtype=torch.float32)\n","        self.alpha, self.gamma, self.reduction = alpha, gamma, reduction\n","\n","    def forward(self, logits: torch.Tensor, targets: torch.Tensor):\n","        ce = F.cross_entropy(logits, targets, reduction=\"none\")\n","        pt = torch.exp(-ce)\n","\n","        if isinstance(self.alpha, torch.Tensor):\n","            if targets.dtype in (torch.int64, torch.int32):\n","                a = self.alpha.to(logits.device)[targets]\n","            else:  # soft labels\n","                a = self.alpha.mean().to(logits.device)\n","        else:\n","            a = self.alpha\n","\n","        loss = a * (1 - pt) ** self.gamma * ce\n","        return loss.mean() if self.reduction == \"mean\" else loss.sum()\n","# ‚îÄ‚îÄ Model, optimizer, scheduler ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","weights    = EfficientNet_B0_Weights.IMAGENET1K_V1\n","base_model = efficientnet_b0(weights=weights)\n","\n","# freeze early blocks\n","total_blocks = len(base_model.features)\n","freeze_upto  = int(total_blocks * 2 / 3)\n","for i, block in enumerate(base_model.features):\n","    if i < freeze_upto:\n","        for p in block.parameters():\n","            p.requires_grad = False\n","\n","base_model.classifier = nn.Sequential(\n","    nn.Dropout(p=0.5),\n","    nn.Linear(base_model.classifier[1].in_features, 2)\n",")\n","\n","try:\n","    model = torch.compile(base_model.to(DEVICE))\n","except Exception:\n","    model = base_model.to(DEVICE)\n","\n","alpha     = torch.tensor([0.05, 0.95])\n","loss_fn   = FocalLoss(alpha=alpha, gamma=2.0).to(DEVICE)\n","optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n","scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS * len(train_loader))\n","\n","# ‚îÄ‚îÄ Training Loop ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","for epoch in range(1, NUM_EPOCHS+1):\n","    model.train()\n","    train_loss = 0.0\n","    for xb, yb in tqdm(train_loader, desc=f\"Train {epoch}/{NUM_EPOCHS}\", unit=\"batch\"):\n","        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n","        xb, yb = mixup_fn(xb, yb)\n","        with autocast(**AMP_KW):\n","            logits = model(xb)\n","            loss   = loss_fn(logits, yb)\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        scheduler.step()\n","        train_loss += loss.item()\n","\n","    avg_train = train_loss / len(train_loader)\n","    print(f\"Epoch {epoch:02d} ‚îÇ Train Loss {avg_train:.4f}\")\n","\n","    # save checkpoint each epoch\n","    torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, f\"model_epoch{epoch}.pth\"))\n","\n","# ‚îÄ‚îÄ Save final model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"best_model.pth\"))\n","print(\"Training complete. Model saved to\", OUTPUT_DIR)\n"],"metadata":{"id":"UKbs_ggHKz5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: save the best_model.pth in the drive\n","import shutil\n","import os\n","# Copy the trained model to Google Drive\n","drive_output_path = \"/content/drive/MyDrive/best_model.pth\"\n","shutil.copyfile(os.path.join(OUTPUT_DIR, \"best_model.pth\"), drive_output_path)\n","print(f\"Saved best_model.pth to {drive_output_path}\")\n"],"metadata":{"id":"2W6GJ4c14FNx"},"execution_count":null,"outputs":[]}]}